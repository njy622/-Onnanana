{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/12-23대기오염nan처리.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정일시</th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20120101</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>88.3</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       측정일시  이산화질소     오존  일산화탄소     아황산    미세   초미세\n",
       "0  20120101  0.031  0.008   1.17  0.0093  88.3  57.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정일시</th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>20231211</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          측정일시  이산화질소      오존  일산화탄소     아황산   미세  초미세\n",
       "4303  20231211  0.015  0.0227    0.4  0.0024  7.2  3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['측정일시'] = pd.to_datetime(df['측정일시'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정일시</th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>88.3</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        측정일시  이산화질소     오존  일산화탄소     아황산    미세   초미세\n",
       "0 2012-01-01  0.031  0.008   1.17  0.0093  88.3  57.3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('측정일시')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03', '2012-01-04',\n",
       "               '2012-01-05', '2012-01-06', '2012-01-07', '2012-01-08',\n",
       "               '2012-01-09', '2012-01-10',\n",
       "               ...\n",
       "               '2023-12-02', '2023-12-03', '2023-12-04', '2023-12-05',\n",
       "               '2023-12-06', '2023-12-07', '2023-12-08', '2023-12-09',\n",
       "               '2023-12-10', '2023-12-11'],\n",
       "              dtype='datetime64[ns]', name='측정일시', length=4304, freq=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "이산화질소    0\n",
       "오존       0\n",
       "일산화탄소    0\n",
       "아황산      0\n",
       "미세       0\n",
       "초미세      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>88.3</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>100.0</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>96.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>70.3</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>53.3</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>62.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>84.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-09</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>72.3</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>80.2</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4304 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소      오존  일산화탄소     아황산     미세   초미세\n",
       "측정일시                                                 \n",
       "2012-01-01  0.031  0.0080   1.17  0.0093   88.3  57.3\n",
       "2012-01-02  0.036  0.0050   1.20  0.0087  100.0  62.7\n",
       "2012-01-03  0.041  0.0063   1.27  0.0073   96.0  63.0\n",
       "2012-01-04  0.024  0.0130   0.83  0.0103   70.3  42.0\n",
       "2012-01-05  0.037  0.0073   0.77  0.0063   53.3  29.3\n",
       "...           ...     ...    ...     ...    ...   ...\n",
       "2023-12-07  0.026  0.0184   0.50  0.0033   62.2  16.5\n",
       "2023-12-08  0.029  0.0300   0.56  0.0031   84.2  22.8\n",
       "2023-12-09  0.027  0.0379   0.61  0.0029   72.3  30.7\n",
       "2023-12-10  0.025  0.0209   0.67  0.0029   80.2  35.6\n",
       "2023-12-11  0.015  0.0227   0.40  0.0024    7.2   3.0\n",
       "\n",
       "[4304 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소     오존  일산화탄소   아황산    미세   초미세\n",
       "측정일시                                             \n",
       "2012-01-01  0.036  0.009    1.0  0.01  83.0  57.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature =  df[['이산화질소', '오존', '일산화탄소', '아황산', '초미세','미세']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>초미세</th>\n",
       "      <th>미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>57.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>0.042</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>63.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.011</td>\n",
       "      <td>42.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.007</td>\n",
       "      <td>29.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-09</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.003</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.003</td>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4304 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소     오존  일산화탄소    아황산   초미세    미세\n",
       "측정일시                                              \n",
       "2012-01-01  0.036  0.009    1.0  0.010  57.0  83.0\n",
       "2012-01-02  0.042  0.006    1.0  0.009  63.0  96.0\n",
       "2012-01-03  0.046  0.007    1.0  0.008  63.0  93.0\n",
       "2012-01-04  0.029  0.016    0.6  0.011  42.0  68.0\n",
       "2012-01-05  0.044  0.009    0.7  0.007  29.0  52.0\n",
       "...           ...    ...    ...    ...   ...   ...\n",
       "2023-12-07  0.026  0.018    0.5  0.003  16.0  62.0\n",
       "2023-12-08  0.029  0.030    0.6  0.003  23.0  84.0\n",
       "2023-12-09  0.027  0.038    0.6  0.003  31.0  72.0\n",
       "2023-12-10  0.025  0.021    0.7  0.003  36.0  80.0\n",
       "2023-12-11  0.015  0.023    0.4  0.002   3.0   7.0\n",
       "\n",
       "[4304 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target =  df[['미세']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4kAAANCCAYAAADLAYkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4lUlEQVR4nOzdd3xUVfrH8e+dSe8JIQk1ICCCKFVAQEREiopdUQF7WRUBRX8r2FFBXV0ba9ldxI6oCKiwgICgIEiTIiUoNRBKes8kM3N/f0QvDgkwyaQRP+/X675Izj1z57lzkzDPnOeeY5imaQoAAAAAAEm22g4AAAAAAFB3kCQCAAAAACwkiQAAAAAAC0kiAAAAAMBCkggAAAAAsJAkAgAAAAAsJIkAAAAAAAtJIoC/vLS0NK1du9anY5SUlOjQoUNVFFHVOnLkiNavX1/bYZRr+fLlys3NrfLjLlq0SNOmTavy4wIA8FdAkgjgL2HAgAF66aWXyt23aNEiXXPNNWXa9+zZI8MwymwtWrSQJC1dulRhYWGSpHXr1qlRo0Y+xWgYhlatWuV1/1GjRumWW24p0/7UU0/p0ksvtb6fN2+ebrzxRq+PGxcXp1mzZnndvzxBQUHlvnbR0dEe/c477zxt2bKlUs/xyCOPlHv+UmnyOWPGjEod9w+33HKL/va3v/l0jPL88XNVmQ8VbrnlFo0aNUqS1K9fPz3//PNVHR4AACSJAHAyW7ZsUWpqqrX9/PPPFXr88RImwzCsN/x1RWpqqtLS0rR161afjrN3714dPHjQYxs1apTat29fRZFKpmnKNM0KP+7SSy897vUwDEP79++vVDxr16494XHvuOOOkx6jU6dO5T42NTW1UjEBAFAZfrUdAADUhKKiIhUUFFTqsTExMYqNjfXp+WfOnKlevXqVaQ8NDfXpuMezePFiNW3aVJJUUFCguLg4rx43btw4xcXF6dVXX9Xw4cOtUdOKio+PL9P2/fff69prr63U8cpz+PDhSo3GffLJJyouLi7TfuDAAXXq1En+/v6ViqdTp07HTebGjBnj1XGXLl0qp9Npfb9u3TpddtlliomJqVRMAABUBkkigHrP7XZry5YtHqWOffr0sd6Mp6enn/Dx48aNU3BwsPX9bbfdZiV8xcXFeuyxx3TgwIETHiMmJkYJCQmVPYXj+vjjj/XFF194tBUXF6tr166aPHmyJGn+/PmaPXv2CY+TmZmpe++9Vz/99JN++uknvfTSS+rVq5c+/PBDXXjhhT7H+b///U/btm3TyJEjfT6WJLlcLi1evFgZGRnKyMioUBIVERFRbvuRI0ckqdJJop+f33E/TCgpKfHquFFRUR7fHzp0SAEBAbr77rslST/++KMGDhxYqfgAAPAWSSKAeu+rr76Sn5+fFi1apB07duj000/X6NGj5Xa7JUkrV67UnDlzjvv4yMhIhYSEWN8HBARYX7vdbv3yyy/KzMysvhM4gSFDhmjixIkebW+//bb279+vfv36SSq9B648fyTPn3/+ud5++21ddNFFWrt2rWJiYvTGG2+oW7duGjFihM466yzddNNN6tu3r5o1aybDMCoUY1ZWlu677z7de++9SkxMLLP/mWeeUcOGDTVgwACNGDHCq2P++9//VlFRkdq0aaO///3v+s9//lOmz4IFC6xYU1NTyyRwycnJuvXWWzVnzhyFhoZaE+j8cZ+pL5577jnFxMTonnvukSTl5uaqTZs2FT7OwoUL1a1bN2tU+M8/hwAAVBeSRAD1WkFBgcaPH69nnnlGv/76q26++WYtWbJE1113nUe/EyWJTzzxxHFHAYOCgjR79mytWrVK55577nGPcf/99ysyMrJMe+fOnfXGG294eTZlxcTEqFOnTh5tCQkJ2rhxo5YuXSpJ2r59e7mPHTlypObPn6+LL75Y3377rTp27Oix/+abb9awYcM0bdo0ffDBBxo/frxWrFih5s2bex1fUVGRrr76akVERFgjm8cKCQlRWFiYAgMDvTrmsmXLNG7cOL377rvq2LGj+vTpo0aNGpVJlvv166cPP/xQksodaczPz9fixYtVUlIiqTSRCw8P9/gQYM+ePZo9e7b8/Pw8JgM6mc2bN3v8zOTm5qpBgwYefebPn6+oqCh16NBBrVu3LnOMjIwMzZo1S8uXL1eXLl2seAAAqG4kiQDqLbfbreHDh6tp06a6++67VVJSov79+2vYsGH67LPPFBQU5NVxtm/frtTUVJWUlMjhcCg3N1ft2rXzOo6vv/5aLpdLkvTyyy8rICBA999/v6Tyk5eqsGHDBmtU7nj3JE6dOlUBAQGy2Y4/h1lQUJDuuecea0SsItLS0nTttddq//79WrZsmUfJ7p+NGzdOPXv29OqYn332me6880498cQTuv766yWVzk47dOhQbdq0Sa+//rqVxAYGBlojcN5o3bq1XnzxRY+21atXa//+/QoJCalQknis++67r8ykPc8//7z8/Pz00EMPlZskPv/88zr77LOtBBEAgJpCkgigXjpy5Ihuv/127dq1S8uWLZNhGAoICNC8efN0ySWXqEuXLvr222/VpEmTkx7rggsukCTrGKGhoXr99de9eqwkXXTRRdbXn376qYKCgjR48ODKndgxVq5cWWaZhrVr1+rCCy/UN998I0l67733yl0qwdskuTJmzpypsWPHqlGjRvr+++99Xh5EKp3U5e6779aUKVM87m3s3Lmz1q1bpwkTJnhM+lKerKwsud1uuVwua5KZvXv36siRIyoqKlLnzp21ePFiK2m97rrr9Pbbb580tqKiIhUWFsrtdsvpdKqwsFA5OTn67bffVFxcrLZt2yo3N1ebNm2y7olcunTpcUeoN27cqDfeeENLly7V7t275XA4JEnZ2dlVUg4LAMCJkCQCqJfmzp2rvLw8LV682ONetIiICC1ZskSfffbZSZO8xMREFRUVyTAM2e122e12j/3r169X9+7dj/v4LVu26MMPP5RpmnK73XK73VqzZo0Mw9Cdd96pwsJC5efnq3Xr1vrHP/5R4XO84IIL5OdX9s94nz59dOaZZ57wsWPHjtVrr71W4eeUdNJlJ+644w59+OGHeuCBB/T00097XUZ6Mv369VNKSkq5I5Lx8fGaOnWq9X23bt3KlHdKpde0sLBQfn5+8vPzU3R0tAYNGqSAgAAFBQUpJCREISEh+uijjyoU27/+9S898sgj1s+Jv7+//P39tWDBAgUGBio4OFjBwcEaMmSIbr/99hMeKyMjQ8OGDdM999yjHj16qGvXrkpKSpIkORwOaxIbAACqC0kigHrp1ltv1a233lruPn9/fw0fPvykxzAMQ4GBgSopKSl3YprmzZvrs88+U1pamlq3bl1m+YPg4GAVFBRYCUlgYKCuueYaBQcHKzQ01NoqUhL5Z1dffbWuvvpqZWdnKyAg4LjlnOV55pln9Mgjj5S77+yzz9aLL75Y6dHOyZMn68knn1SzZs0q9fgT+eMcTdPUxx9/rA8//FAbN25Uenq67Ha7GjdurHPPPVejR48utzw0Ozu7ymOSSktmx40b51XfE91XmJqaqksuuURt27a1PjhYt26dtf+WW27xJUwAALxCkgig3rvwwgs1aNAg/d///V+lHr9ixQqr5PRk/jzKdtppp+n111+XVLp0QYsWLdS4ceNKxXAil19+uQYPHnzcpK884eHhCg8PL3efzWZTVFRUpZfsaNiwoaTSewX/9a9/adasWZU6zomMGDFCixYt0uOPP67XX39d8fHxKi4uVnJysj7//HP17dtXb7/99nE/KNi1a5emTZumZ555pspj+/e//622bdvq/PPPr9DjlixZoltvvVXdunXTRx99VGbkGgCAmnL82QoAoJ5wuVzWchflGTBgQJm1Bv+sX79+Mk3zhNvKlStPGMNNN92kefPmnbDPoEGDyqyTVxUuvvhiffLJJ1V+3JNJS0vTzz//fMI+P/zww0lLY4+1detWffLJJ5o9e7ZGjRqltm3bKioqSnFxceratauef/55PfXUU3rssceOe4x9+/adtMS3U6dOOvvssysUmyR98sknJ/x5CAkJ0SWXXFLmntDGjRvr/vvv1xdffFGhUWEAAKoaI4kA/vJiY2OPuwh6TZo/f361HDcuLq7c2U3rgj59+lT6sRVdr7Gixo4dWy3HjYuLsyYV+rMzzjhDZ5xxRrU8JwAAFUGSCOAvoaioSFlZWSfsExYWVu5EMFUlLy9PaWlpJ+wTGBh43DLQEykoKDjpsSMiIjzWAKwJLpdLhw4dOmGf4ODgcteQPJ727dtr2LBhuvzyy/X444/roosuUkJCgoqLi7Vv3z598cUX+uc//6l//etfJz3WyV4zSZX6AMGb6/HHJDkAANQ1JIkA/hKefvppPf300yfs8/XXX/u0Ft7JPPDAA3rggQdO2Ofyyy/X7NmzK3zsZ5555qT3102fPt1aW7Cm7N+//6TLXwwbNkyffvpphY77ySef6IMPPtDHH3+siRMnKiMjQ3a7XY0aNVLPnj21ePHik45SOhwO6/7JEykpKanwhwfeXI9HH31Uzz77bIWOCwBATTDMk81lDgA4qZ07d+rJJ5+s8NIJddGcOXPUrVs3r9eBRO0YP368unbtqmuuuaa2QwEA1DMkiQAAAAAAC7ObAgAAAEAdY5qmPvjgA/Xs2fO4fX7++Wf17NlTiYmJat++vRYuXFglz809iQAAAABQh8yfP18PP/ywCgoK5O/vX26f3NxcDR06VO+9954GDBig77//Xpdddpm2b99e6bWO/8BIIgAAAADUIXl5eZo0aZKmTp163D7Tp0/XOeecowEDBkiS+vbtq/PPP18zZszw+fkZSQQAAACAOuSPScmWLl163D4rV65U7969Pdq6d++uDRs2+Pz8jCQCAAAAQDVzOBzKycnx2BwOR6WPl5KSovj4eI+2uLg4paen+xpq3RhJnOvftrZDQA166coPajsE1KBpEZNqOwTUoIgWvt0DgVNLSJeutR0CapBz3+7aDgE1KOxvk2s7hEqrq7nFmkdvKLNm85NPPqmnnnqqUsdzuVw6dqEKl8slwzAqG6KlTiSJAAAAAFCfjR8/Xg8++KBHW2BgYKWPFxMTo7S0NI+21NRUnyetkSg3BQAAAIBqFxgYqIiICI/NlySxa9eu+vHHHz3aVqxYoXPPPdfXUEkSAQAAANQfhr9RJ7eqNnz4cC1evFhLliyRJM2bN0/bt2/Xtdde6/OxKTcFAAAAgFPARx99pDVr1ui1115T06ZN9emnn+ree+9VRkaGWrdura+//lqhoaE+Pw9JIgAAAADUQf369dP27dut70eMGKERI0ZY3w8aNMhjf1UhSQQAAABQb9j8qr6086+GexIBAAAAABaSRAAAAACAhXJTAAAAAPWG4c84mK94BQEAAAAAFpJEAAAAAICFclMAAAAA9Qazm/qOkUQAAAAAgIUkEQAAAABgodwUAAAAQL1h+FNu6itGEgEAAAAAFpJEAAAAAICFclMAAAAA9Qazm/qOkUQAAAAAgIUkEQAAAABgodwUAAAAQL3B7Ka+YyQRAAAAAGAhSQQAAAAAWCg3BQAAAFBvMLup7xhJBAAAAABYSBIBAAAAABbKTQEAAADUG4adclNfMZIIAAAAALCQJAIAAAAALJSbAgAAAKg3bJSb+oyRRAAAAACAhSQRAAAAAGCp0iTxH//4R1UeDgAAAAAqxLAZdXI7lVQ6SUxNTdWoUaM82l555RWfAwIAAAAA1J5KJ4kzZsyQ2+32aDNN0+eAAAAAAAC1p1Kzm2ZlZen111/XvHnzPNoN49QaRgUAAABQvxh2pl3xVYVfQdM0dccdd2jEiBFq3bp1dcQEAAAAAKglFUoSd+3apaFDh8rPz09PPPFEdcUEAAAAAKglXpebhoWFqbCwUJdccok+/fRTSaWT15x22mkyDEOmaaqwsLDaAgUAAACAk7HZuQXOV16PJO7Zs0cLFizQgQMHNGbMGElSw4YNtX//fiUnJys5OVmxsbHVFigAAAAAoPp5nSTGxsZqwIABWr58uTZt2qSXX35ZkhQZGanIyEhFRUXJZuMmUQAAAAA4lVV4dtPg4GB9/PHH6tmzp6666iq1bNmyOuICAAAAgAo71Raur4sqNfTXuHFjjRo1Sq+++moVhwMAAAAAqE2Vrg+98cYblZyc7NFmmqbPAQEAAAAAak+Fy03/0LRpU82cOdOjbdiwYT4HBAAAAACVxeymvvNpphnD8LwAlJ8CAAAAwKmN6UgBAAAAABavyk23bdumNWvWlGnv0qWLtm3bpsLCQklSWFiYrrrqKl1//fX69NNPqzZSAAAAADgJg3JTn3mVJCYnJ+vbb78t0x4VFaUxY8Zo8ODBMk1Ty5Yt01VXXaVly5ZVeaAAAAAAgOrnVZI4cOBADRw4sNx9d999t959911J0mmnnVZ1kQEAAAAAapzX9yR+/vnnHt+/+eabKikpqfKAAAAAAKCyDJutTm6nEq+jHTNmjPX11q1bNXXqVNnt9moJCgAAAABQO7xOEk3TlCRlZWVp5MiReu2112Q7xTJiAAAAAMCJeZ3lFRYWauLEierWrZtGjhypPn36SCq7ViIAAAAA1BbDZtTJ7VTidZLodDqVlJSkoqIiJSQkWO1/jDBKUkFBgRYuXMi9igAAAABwivJqdlNJioiI0Mcff6yUlBRdeeWVioqK0uDBg9W/f3+rT+fOnfXKK6/onHPOqZZgAQAAAADVy+sk8Y8Rw8aNG+vLL7/URRddpD59+ujjjz+2+vzvf/+r+ggBAAAAwEs2+6lV2lkXeZ0kPvTQQ9bXTZo00T333KMDBw6obdu21RLYqa7JiMuV+Lcb9WOfYeXuj+jUTh2mPKXAhIZy5Rdq67hJSlu0wtrfYvTNanHPcNmDg5S1drM23f2YStIzayp8VFB8wwA9dPdpatooSC6Xqfc+369FP6Sf8DHtWofqzUkddO+jW7Tt1zyd2zVKo29t4dEnIMCm4CCbLr5pbTVGD28Z/gGKuf4OBXfoLBk25a/+QZkz35f+VHYvSSGdeijqyhGyBQXLlZOpjBnvyvHbNmt/xIChCu9/iQz/ABXv+VVp70+ROy+3pk8HJ+Pnr5CBw+Tfqr0MwybHljUqXPylpKPXO/SyW+TXvI3Hw2wh4XJs/FEFCz612uxNWirs0puU89ErMvNzauoMUAFFxSV6cdZ3+jFpj1xuU0O6nKGxl/aV7Zj7iK79xwfKzC+U/++T97VtGqdXb7vco8+mPSl68tMF+s+91yk2IrTGzgHeK3K69NJ3G7Vy72G5TVOD2jbT6PM6yHbMXBumaerj9b/py827VeR0yd9m0xc3XyR/u00rdh/SlBVblOcovc3qyrNa6LbuZ9TG6QBVzuskcdy4cR7f33///VUeTH3QcOB5OuOFh2UPDpZZ4iy3jz0sVN1mva2Ntz+i9CUrFdOnm7rNekvLOgyR43CaGl0zRE1HXK4Vva5VSXauOrz+hM5+a6LWXcdrXhfZDGnS39vqs68PasGyNDVvEqTXJ7bX7n2F2rm34LiPu/napnK5jr7ZXLkuSyvXbfDo88CdLZSdU/7PEWpe9HW3Sjab9o+/W0ZgkBIenKjw/pcod/E3Vh+/2DjF3jZGh/7xqIqTdyuofUfF3f+o9j9yl8zCAoV0663Qcy/QwecekrugQDHD71KDm+5T6pvP1+KZoTwhA66RDEPZUx6TERCg8OEPyH1OPznWfGf1yf/qPc8H+Qcq6t5nVPR7H1t0rEIG3yh7TJzs0Q1rMHpU1MtfLZPbNPXNo3eosLhEd7/1uaYv/1nD+3bx6JdTUKT37r9eTRtEljlGclqWJs1crH2pmdqfnl1ToaMSXlm2SW6ZmnPbIBWWuHTvzB80Y8NO3dC5tUe/qauTtHrfEf33ur6KCQlSal6h7L9/cBATEqh3rjlPEUEBSs0r1M2fLlXrBpHq26pRbZwSUKV8WsNi//79VRVHvWEPC1HSY69o012PHrdP4+svUfbazUpfslKSlLF8rdK/X6NG110sSWo5+ib9+sy/VJKZLbndSnryNcVd0k/+0WX/Q0Lt63JWpFwuUwuWpUmS9h0o0qIf0jWoX+xxH9OzS5TcblOp6cXH7dMoLlB9zonRjK8OVnnMqDgjMEhhvfor84v3JbdbZmGBsud9obDeF3r082/SQiVHDqo4ebckqWjrRpkOh/zjGkuSIgZcpqyvP5U7P08y3cqa/bFCzu4mW2hYjZ8TTsA/UIFnn6vCJV9Kplumo0iFK/6nwI69TviwoB4XqmTnL3JnHJYkGQHBKkn6WdnvPF0TUaOSChzF+mrNFo0d2ld+dpvCgwN1+4AemrP6lzJ9swuKFBEcWO5x8ooc6n9Wa838v5urO2T4oKDYqW+27tPoPh3kZ7MpPNBft3Zvq6+37PXol1ng0HtrkjRxcDfFhARJkhqGBVujje3ioxURFGC1nxkfrSN5hTV7MihXbc9i+pea3fRY+fn5HpPWoNShLxfoyNzvTtgnumcnZf643qMte80mRXQ8Q4bdrsiuHZTxp/0l6Zkq3Jui8A6nV0vM8E3708P0S5JnqeD23/LUOrH8EqPgIJvuGdlc/3p/b7n7/3DjFY01Z8Fh5Re6qixWVF5AYis50w7LnX/0Wjt271BA4+bSn9aMdfy6RbaQUAW17yhJCu1+ntwFeSrev0ey2RTYopVH6ak7L1fO9FT5N0mssXPByfk1ai5XVprMwnyrzZmyR/aGTSTjOP91+gco6JwLVLh8rtXkOpwsx/ofJCezftdlW5MPq0lMpKJCg622Ds0TtPNgupwut9VW4nKpqKREYUHlJ4ntmsbr2l4dFRTgX+0xo/K2HclUk8hQRf0p2e+QEKPf0nPkdB+93j/sPqjOTWKVEB5ywuO5TVOr9h7W3sw8XdimSbXFDdQkr8pN9+3bV6atoKBATqdTycnJHstg/KF58+a+R1dPBTWKU/p3P3m0OVLTFdW9owIaxsiw28vcf+hIzVBAg6gajBLeio32V2qG54hgZnaJIsLL//V68M6WWrw8XQcOOY57zMhwP/XrFaORozdWaayoPL+oGLlysjzaXLnZMvz8ZAsOKR0ZlOQuyFfGjHcVP/YpmcUOGX5+OvjCBMnllD0yWrLZytx/6MrNlj0svKZOBV6whUfJzPe8TmZ+jgy7XUZgkMyisqXkgR17y5m8U+6sE9+PjLonNSdPDcI9P9iLCQ+R0+1WfpFDkb8njzkFRTJk6JLn/is/u11dT2uiURf34b7DU0xqXpFiQjwT/ejgQLncpvKLnYr8fXTwt7QcJYQH67lF67Vy7xGFB/preJfWurT90Q/1Rn6yRL+l5SgiKEBPDuyq6JDyP0AATjVeJYm9e/eWYRjlJoO9eh0tvfmjj2EY2rx5syIjy5ZHOhwOORyeb45LTLf8j/fJbD1k2O2SUbbNNE0Z9vJfB8NuK/f1R+2z2QwZx1xQm80oM5mJJF18QUM1jg/S5Ck7T3jMgX1jtXx1prK4H7HusNl07C+u8cffrT9d64CWbRQz7DYdfHacivftUlC7joq75+869MJ4me7yR4UNw/bnuVBQFxi2Mn+njzuC+LvAzr1VsPCz6osJ1cblNsv8H+t2l35v/GkikwbhoVr/8gMyDENZ+YV6fe5yjf7vLH38wHCPfqjb3KZZ5k+u+/fr/+ermF/s1A+7Durpwd004cLO2pGarfu+XKGE8BB1a1Z6j/GHN/aXy21q88EMPbVwre7p1V6D2jarmRPBcRm2v05eUV28ShKTk5NP2qeoqEgrVqzQhRdeeMJ+kydP1tNPe96bcYMRo+H249+/Vd8UZ2QrIDbaoy0gNkaOw6kqycyRDEP+0ZGl9yR67E+r6VBxjOlTOllf79xXoMde3KHcPKciIzx/laIi/JWR5VleltgkWLdd31Sjn9gq90kSgsEXNNSbJylHRc1y5+fJHh7h0WYLj5Tb4ZC78OioUsSFQ5X73TwV79slSSratlEFP69SWN+Byp77uSRDttAwa+Sx9DgRcmUze3FdYhbmywj2vE/UFhous6RYZlHZe47sjRJlCw6Tc++OmgoRVSgyJEhZ+Z7XNTOvQEH+fmVKS/9IBqNCg/XoNReq9/gpOpCeraaxUTUVLnwUERSgrELPAYvMQocC/ewKCzxaKhwVHKCeifE6NzFektQ2LkoXt2um73cdtJJESbLbDHVq0kB39minGRt2kSSiXvA6zd6xY4ceeeQR6/u8vDyPT93y8vL0+OOPn/Q448ePV3Z2tsd2nS2mgmGf2rLXb1F0z84ebdG9uihr1Qa5CgqVn7Rb0ece3R+Y0FCB8Q2Us3F7TYeKY9wwaoO1PfZi6ZvBHbvydebpnm8mO5wRpi2/5nm0De4Xq5Bgu955voO+ntZVX0/rqrjYAL302Bm66Zqj9zC0SgxRbEyAft7CNPl1SfHenfKPbyJbyNGysqDW7VS8Z4fHSKLh5yfTdcyIodstw+4ns9ihksMHFNjq6BTp9sho2SOiVLx/d7WfA7znPLRP9gbxMoKO3ovk17SVnCm7Vd6wb2CHHire/nMNRoiq1K5pvPYcyVROQZHV9vPuFHVonlBmCYw/M83SJRL8/ew1ESaqyBlxUdqbmaecoqO3imxMSVeHhGiPJTBaNYhQfrHnB76GYSjwONfb325TED8LqCe8ThJzc3O1adMmSdLtt9+uRo0aKT4+XosXL5YkhYWFKTf35Ot8BQYGKiIiwmP7K5WaSlLK9K8U2/9cNejXU5LUcHBfhbVtqYNfzJck7Zs6Q20eHyW/yHAZ/v5q+9yD2jf1c7kLi050WNSSH9dlqUF0gAac10CSdPppoerVNVpzF6d69Hvn42RdfNNaDb11nbUdSSvWQ89u1wdfHLD6de8UqY1bc/Sne+dRB7hyslT4y3pFXTVSstlkCwtX5CXXKOfbrz365a9Zroj+l8geU1odEdD8NIX27KeC9T9KkvK+X6ioodfLFhwq2f0UfdVI5f7wrczi4890i5pn5ueoZOcWBV9whWTYZASHKqj3EBX9tLjc/v6tzlTJHj7IO1XFRoSqd7sWen3ucjldbmXmFWjqop80/HzP5S+S07K050iGJKnY6dSLs5aoQ2IjxUdxT/GpJDY0SL0S4zVlxRY53W5lFjr07uqkMstf9G/TRFsOZeqnvUckSbvTczR/e7IGnt5UkjRjw04riUzJzte7q5N0RYcWNXouKF9tz2JaH2Y39XqdxD/MnTtXO3fuVFpamvbs2aPLLrtMSUlJCgwMLHOvIY5qcuNliux2lrY++JyKDhzW+uEPqsMbT8o/JlIFO/dq7ZX3yFVQWuqy+/UPFNQ4Xv22LpDpdOnw14uVNOGlWj4DHI+j2K1HX0jSuLtP0703JSojq0TPvv6b0n6fzOb+WxO17dc8LVru3WQW7dqE6dfd+SfviBqX9v4bir35fjV7+T2ZjiJlL5itgg0/KbTn+Qps0UYZn/5XBet+lC0kVPFjn5ItMFDu/Dylvf+GHLtKR55zFn0te1SMmjz3pky3WwUbflLmzPdr+cxQnvxvPlDopTcpauyLMkscKlr1rUp2bFRAhx7ya5xo3X9oBAbLHpsg16Gyk7zh1PHUsIF6asZCDXjybQUH+OumC7qp/1lt9M3ardqy75D+flV/ZRcU6ZEP56qoxKlAP7t6nJ6ol28ZWtuhoxIeH9hFzyxcr0H/nqdgfz+N7NpGF7RurHnb9mnLoUw9fEFHBfnZ9Y+hPTV5yc/KXOhQdHCgnrioi9o0LJ1z47e0bF05baEC/OyKDArQbd3bamDbprV8ZkDVMEwvZkOZNWuWkpKStGzZMp199tnq3Lmzrr/+eknSlVdeqQsvvFBxcXF6+OGHtXdvxe+jmuvftuKR45T10pUf1HYIqEHTIibVdgioQREtEmo7BNSgkC5dazsE1CDnPsri/0rC/ja5tkOotM2XXlDbIZTrrG9OvExeXeLVSOJXX32lgwcPymazqaioSKGhR+/JCQkJ0bx58xQZGSmnk5kYAQAAANQem/3UKu2si7y6GXDatGl67rnnZJqm2rVrZ92H6HQ6tXr1an3xxReaPn26/PwqXL0KAAAAAKhDKpTVGYahkSNHqmvXrrrmmmu0d+9eXX311QoJCbH2AwAAAABOXRVKEk3TVGhoqFatWqW5c+cqLi5OF110kbWfJBEAAABAbTrVZhKti7xOEjt37qyZM2dKkqKiojR8+PAyfe66666qiwwAAAAAUOO8XqDQZrNZZaXHM378eJ8DAgAAAADUnkrNNDN58mQ1bNhQd9xxR1XHAwAAAACVZti8HgfDcXj1Crrdbo/N5XLJ6XR6tP3Zf/7zn2oJFgAAAABQvbxKEv38/OTv729tTzzxhO699175+/tb+5544gmr/6OPPlptAQMAAAAAqo9X5abHjhSejGmalQoGAAAAAHzB7Ka+86lg1+FwKCMjo0w7S2EAAAAAwKnJpyTx+eef14svvlhVsQAAAAAAalmlZjeVpA8//FBfffWVli1bVpXxAAAAAEClUW7qO6+TxCNHjsjtdmvHjh165513tHv3bs2fP19hYWHVGR8AAAAAoAZ5nST26NFDLpdLKSkpio6O1rfffquGDRtKKp2oJjk52fq6ohPdAAAAAADqBq+TxN27d0uSCgoKNH36dF199dWaOHGihg8frqysLPXo0UOGYcg0TQUEBFRbwAAAAABwPJSb+q7C9ySGhITo9ttv15AhQzR48GD5+/vruuuu08GDB6sjPgAAAABADar07KaNGzfW7NmzNWnSpKqMBwAAAABQiyo9u6kknXbaaVq1alVVxQIAAAAAPjFsPq3yB/m4TqIkBQUFVUUcAAAAAIA6wKuRxAsuuECGUbEbQOfMmaPw8PBKBQUAAAAAqB1eJYmPPfZYhQ8cEhJS4ccAAAAAgC9sdmY39ZVXSeKFF15Y3XEAAAAAAOqACk9c43K5lJycrNTUVDVp0kSNGzeujrgAAAAAALXA6yTRNE1NnjxZr776qmJiYhQTE6OUlBT5+fnp6aef1vDhw6szTgAAAAA4KcNGuamvvE4SH3nkEf38889as2aNEhMTrfY1a9ZoxIgRstvtuv7666slSAAAAABAzfB6CYwPPvhAn3/+uUeCKEnnnHOOpk6dqqlTp1Z5cAAAAACAmuX1SKLT6Tzumojh4eEqLi6usqAAAAAAoDIMm89Lwf/lef0KXnrppbrvvvvkcDg82jMyMjR27Fhdd911VR4cAAAAAPzVFBYW6q677lJiYqKaNm2qhx9+WG63u0y/2bNn68wzz1Tz5s3VvXt3LV++vEqe3+skccqUKXK5XEpMTNTQoUN1yy23aODAgWrfvr369++v++67r0oCAgAAAIC/snHjxsntdmvnzp3asmWLli5dqilTpnj02b17t26++WZ99NFH2rdvn5577jlddtllys7O9vn5vS43DQ0N1bRp03To0CFt2bJFaWlpaty4sTp27KiIiAifAwEAAAAAX53qs5vm5eXp/fff1759++Tn56fIyEhNmDBBEydO1OjRo61+mzdvVps2bdS5c2dJ0kUXXaSQkBD9+uuv6tatm08xVHidxISEBCUkJPj0pAAAAACAstatW6eWLVuqQYMGVlv37t31yy+/yOl0ys+vNIU777zzlJmZqW+//VYXXXSRpk+frpiYGJ199tk+x1DhJBEAAAAAUDEOh6PM/C6BgYEKDAz0aEtJSVF8fLxHW1xcnJxOp3JychQTEyNJio6O1iuvvKJBgwYpJCRExcXF+uGHHxQQEOBzrEz9AwAAAKDeMGxGndwmT56syMhIj23y5Mll4ne5XDJNs0ybJBnG0VLa1atX64EHHtDatWuVm5urefPm6ZprrtGePXt8fg1JEgEAAACgmo0fP17Z2dke2/jx48v0i4mJUVpamkdbamqqgoODFRkZabW99tprGjVqlLp06SLDMDRgwABdeeWV+s9//uNzrJSbAgAAAEA1K6+0tDxdunRRUlKSMjMzFR0dLUlasWKFunfvLtuf1oAsLi627k/8g81mq5L16xlJBAAAAFBvGDZbndy8lZCQoMGDB2vChAlyOp1KS0vTpEmTNHbsWI9+1113nd544w3t27dPkrR+/Xp99NFHuvrqq31+DRlJBAAAAIA6ZOrUqbr99tvVqFEjhYaG6qGHHtIVV1yhjz76SGvWrNFrr72ma6+9VllZWRo8eLDy8/MVHR2tqVOnqmfPnj4/P0kiAAAAANQhsbGxmjNnTpn2ESNGaMSIEdb3d955p+68884qf36SRAAAAAD1hmEzTt4JJ8Q9iQAAAAAAC0kiAAAAAMBCuSkAAACAeqMiM4mifLyCAAAAAAALSSIAAAAAwEK5KQAAAID6w2B2U18xkggAAAAAsJAkAgAAAAAslJsCAAAAqDcMG+WmvmIkEQAAAABgIUkEAAAAAFgoNwUAAABQbxg2xsF8xSsIAAAAALCQJAIAAAAALJSbAgAAAKg3mN3Ud4wkAgAAAAAsJIkAAAAAAAvlpgAAAADqDWY39R2vIAAAAADAUidGEl+68oPaDgE16KFZN9V2CKhBIwb/u7ZDQA1q3fSM2g4BNah/aHxth4AalJtY2xGgJt1X2wGgVtWJJBEAAAAAqgKzm/qOclMAAAAAgIUkEQAAAABgodwUAAAAQL1BuanvGEkEAAAAAFhIEgEAAAAAFspNAQAAANQfNsbBfMUrCAAAAACwkCQCAAAAACyUmwIAAACoNwyD2U19xUgiAAAAAMBCkggAAAAAsFBuCgAAAKDeMJjd1Ge8ggAAAAAAC0kiAAAAAMBCuSkAAACAesOwMbuprxhJBAAAAABYSBIBAAAAABbKTQEAAADUH8xu6jNeQQAAAACAhSQRAAAAAGCh3BQAAABAvcHspr5jJBEAAAAAYCFJBAAAAABYKDcFAAAAUG8YBuNgvuIVBAAAAABYSBIBAAAAABbKTQEAAADUH8xu6jNGEgEAAAAAFpJEAAAAAICFclMAAAAA9YZhYxzMV7yCAAAAAAALSSIAAAAAwEK5KQAAAIB6w2B2U58xkggAAAAAsJAkAgAAAAAslJsCAAAAqD8MxsF8xSsIAAAAALCQJAIAAAAALJSbAgAAAKg3mN3Ud4wkAgAAAAAsJIkAAAAAAAvlpgAAAADqDxvjYL7iFQQAAAAAWEgSAQAAAAAWyk0BAAAA1BuGweymvmIkEQAAAABgIUkEAAAAAFgoNwUAAABQfzC7qc94BQEAAAAAFpJEAAAAAICFclMAAAAA9YZhY3ZTXzGSCAAAAACwVDhJzM/Pt77u1KlTVcYCAAAAAKhlXiWJzz77rPX1iy++qK+++kqSdODAgTJ9f/311yoKDQAAAAAqyLDVze0U4lW0b775pvX1unXr1K5dO0mSYZSt9z3//POrKDQAAAAAQE3zKkk0TVNS6chhenq62rRpc9K+AAAAAIBTj1ezm/4xYvjII4/o//7v/7zq+1cX3zBAD919mpo2CpLLZeq9z/dr0Q/pJ3xMu9ahenNSB9376BZt+zVP53aN0uhbW3j0CQiwKTjIpotvWluN0aOimoy4XIl/u1E/9hlW7v6ITu3UYcpTCkxoKFd+obaOm6S0RSus/S1G36wW9wyXPThIWWs3a9Pdj6kkPbOmwkcFJcQF6u+j2qpZk2A5nabenb5HC5ceKdMvPNRP33zcS0fSHFbb7P+l6OOZyR79Bl8Qrysvbqy7H/652mNHxcVG2XTL0AglNPCTy21q9tJ8rdxUVKZfi8Z+GnlxuMJDbbLbDK3dWqQZ3+bJ7S7dP6R3iPp2DlaAv6GCIrdmLsnXhiRHmeOgdmWl7de8Dx9X+uE9stv9dN7QUTqr5+Xl9t2y+hv98M2/VFyUr5i4RF16yyRFxTYr02/eR09oX9Jq/e2Z+dUdPiooJ32/Fs94XFmpe2Sz+6nH4FE6o1v511uSMg7t1OIZj6rP5Y+oUYtOVruzuEjLZj2nfduXy+12qW2XS9R76MMyWNS9djC7qc+8ShILCwt1yy23yM/PTxdffLG+/PLL6o7rlGYzpEl/b6vPvj6oBcvS1LxJkF6f2F679xVq596C4z7u5mubyuU6OhK7cl2WVq7b4NHngTtbKDvHWV2ho4IaDjxPZ7zwsOzBwTJLyr8u9rBQdZv1tjbe/ojSl6xUTJ9u6jbrLS3rMESOw2lqdM0QNR1xuVb0ulYl2bnq8PoTOvutiVp33f01fDbwhs0mvfB4B306e7/+t/iwEpuG6M0XOmnX3nz9tjvfo294mJ9S0x269o6fyj1Wjy7RuvfW0xQUaJfTRRVGXWQY0pgborRgZYGWbyhSo1i7Hr0tRgeOOLXvkOfvvKPY1BszspWV61ZIkKGHb4pW/27BWrS6UJK0a3+JFq4skMstnZ7or4dGROuBf6Yqv5BrX1e43S59NuUe9Rh4qzr2ukppB3fqgxdvVMMmpyuhWTuPvvt3/qzvZv1TIx/6SJENGmvF/97RzLfH6PbHPN8jZaen6JdVXykiOqEmTwVecLtd+vq/96hzv1vVvsdVyji0U1+8fqMaJJyuhk09r3dhfqa+++xJpexerxJHfplj/TDneZmmWzc/9q1Kigs1681btPGHj9Tp/Jtq6nSAKuXVxxtFRUWaP3++hgwZovz8fH344Yf68MMPqzu2U1aXsyLlcplasCxNkrTvQJEW/ZCuQf1ij/uYnl2i5HabSk0vPm6fRnGB6nNOjGZ8dbDKY0bl2MNClPTYK9p016PH7dP4+kuUvXaz0peslCRlLF+r9O/XqNF1F0uSWo6+Sb8+8y+VZGZLbreSnnxNcZf0k390ZI2cAyqma8douVym/rf4sCRp7/4CLVx6WEMuLPsGMDzcT3n5x/9QJzjIrn9/sEfPv55UbfHCN+1PC5DbLS3fUDpyeDDNpR83Fal3x6AyfQ+muZSVWzpsWFBkKmlPsaIj7Nb+pL0lcv0+qrhjb4mKS0xFhDLKUJfs2bZSNrtdHXtdJUmKbdRKHXoM1eYfZ5Xpu/a7j9R9wM2KbNBYknTuwNuVnX5Ah5O3e/T79rPJOvv346FuSd6xUobNrvY9Sq9PTEIrte02VNvWlL3ezuIiJbTopBGPzFVQSLTHvmJHvratma3eQx+Sze6nwOBwnXPR37R1NYMqOHV59b9TdHS0Nm/erGeffVa5ubmaNWuWZs0q+wuEUu1PD9MvSbkebdt/y1PrxNBy+wcH2XTPyOb61/t7T3jcG69orDkLDiu/0FVlscI3h75coCNzvzthn+ienZT543qPtuw1mxTR8QwZdrsiu3ZQxp/2l6RnqnBvisI7nF4tMcM3HdpGaPO2HI+2rTty1aZlWJm+4WH+yj1Bkrj0xzStWHPiMnTUrtZN/fVrcolH2+4DJWqe4H/Cx7Vs7KczWwVo+YbCMvv8/aSBPUO060CJDqbx97wu2b9rg5q26uLR1rjl2TqcvK1s350/e/S12f2U0Ly9R99fN32novwstes6qPqCRqUd2rNBjVt6Xu/45mcr9UDZ6x0e3UhdLrhNQSFlP8A9krxFETFNFRx6NHmMb362Mg7+KreL6q/aYBi2OrmdSrwqN5Wkhg0b6vnnn9fTTz+td999tzpjOuXFRvsrNcNzRDAzu0QR4eW/3A/e2VKLl6frwKHj35sSGe6nfr1iNHL0xiqNFdUvqFGc0r/zLDd0pKYrqntHBTSMkWG3l7n/0JGaoYAGUTUYJbwV2yDA4x5D6fi/3xFhfmrbKlwz3+2h3DynvluRqo9nJsvppLzwVBEVblNmjtujLSffrbCQ8u93uX9YpDq0CpTLbeqjebkeSWDDaLseuSVa0RE27Ulx6q0vsqs1dlRcXtYRhUfHe7SFhDdQYX5W2b7ZRxQWEXtM3xirb27WYc3/ZKJuHDtVedmp1RUyfJCffURhUWWvd1E51/tkxwkJb+DRFhweI7fbqeKiPAWFRvkYKVDzvE4SJeniiy/W+PHjlZeXp7Cwo5+aDxo0SIWFhTJNUxkZGSc8hsPhkMPh+QbL7SqWzR5QkVDqNJvNkCGjTJvKmfn14gsaqnF8kCZP2XnCYw7sG6vlqzOVxf2IpxzDbtcxPw4y7HaZpinDXv6nSobdxkzBdZTNZpSZoOs4l1HfrUjVkuWlbw6bNQ7W+DFtFRbqp3+9u6u6w0QVsdmMMr+/Nlu5f84lSW/MyJZhSE3i/HTbZRGKDLfpfytK70VPzXRp3Ctp8veTurYL0uN3xOi5qRk6nMFoYl3hNl2SPC+u6XaV3px6bF+3u8zfadPtlmTIdLs1+78PqefA29Ug4TSSxDrKbbrKXEO321XhSRjNcn9ufv9wiQkdcYryKkls2LCh9XWfPn20YsUKDRp0tHTi8ccfl8vl3X9ykydP1tNPP+3Rltj+drU8806vHl/XTJ/Syfp6574CPfbiDuXmORUZ4fnSRkX4KyPLs2QpsUmwbru+qUY/sVXuk+QDgy9oqDdPUo6Kuqk4I1sBsZ73LwTExshxOFUlmTmSYcg/OrL0nkSP/Wk1HSqO8fl/e1hf79yTp0ee3aKc3HJ+vyP9lZ5Z9n7iP7/3SE4p1L/e3amJf29PklhHvTT26KhQ8mGnXpuepfxCt8JDPD8FCA+xKTvPfezDLaYp7T/s1KcLcvW3ayKtJPEPJU5p1eYitW8ZoN6dgvTlkrKTYKD6TRnf3/o6rsnpum7U2woOiVRBXpZHv4LcDIVFNNSxgkMjVZCXad2TKEkFeRkKi4zVD9/8SwFBoep2wfBqix8VM+3po9c7tvHpGnrn2woKiSwzaliYl6GQ8LLX+0SCQqJUmOdZEVSYlyE//yAFBoVXOmb4gNlNfeZVkrhx49ESx1tuuUWnn156r9Qfn7706dPH6yccP368HnzwQY+2obeeuiWUN4zaUKZtx658DbuskUdbhzPCtOXXPI+2wf1iFRJs1zvPd7DaQoLteumxMzTj64P64IsDkqRWiSGKjQnQz1s874PCqSF7/RZF9+ys3XrPaovu1UUHP5srV0Gh8pN2K/rczjoyb6kkKTChoQLjGyhn4/byD4gaU96spEm/5erGqzynuD+rXaS2bD/576fNZqikhBHiuuqhV8t+MLMnpURDenveT96mub927i8p0/dYJS5TxSe43ifbj+o1avKSMm2NEjto5cL/erQl71yvJqd1KtM3ofmZ2r/zZzVKPFOS5HIW6+CeX3TJTc/q28+eV0lxgV4ee46k0tEpZ3GRXhrTTbdN+EIx8S2q/HxwYrc+WfZ6xzXtoPXfeV7vg7vXK+FPS1t4o2HT9so8sltFBdnWPYsHd69XfPOzWQIDp6wK/+Sec845iows/QWYM2eO1e5taVxgYKAiIiI8tvpUaipJP67LUoPoAA04r7Q+/fTTQtWra7TmLvYsN3nn42RdfNNaDb11nbUdSSvWQ89utxJESereKVIbt+ZYa23h1JIy/SvF9j9XDfr1lCQ1HNxXYW1b6uAXpetl7Zs6Q20eHyW/yHAZ/v5q+9yD2jf1c7kLy67Dhtq3Yk26YmMCNLBfnCSpbesw9eneQF8vLDvrcPvTwxUeVvpZXEyUv+655TQt+O5wjcYL32zY4VBUuE3nnl06m2mLxn7q1DZQy9aXnZCmb5dg617F8BBD11wYpmXrSvtFhdvUo0OQ/ni/eHqiv7q0DdTqLayTWJe0OfsC5WUd0eZVpe9vUvZs1q8bl6jTedeW6du57zD99O27ysk8JLfbpR/mvqnEM3oqKraZxr60XA+/vl4PvbZWD722VsNGva2YuEQ99NpaEsQ6pGWHC5SffUTb15Ze78P7Nmv3L0t05rllr/eJhEY0VGK787Tym3/K7XKqMC9Da759W53Ov7k6wgZqRIXuSTxWr169rK8TExO1b98+nwOqDxzFbj36QpLG3X2a7r0pURlZJXr29d+U9vtkNvffmqhtv+Zp0XLvZjVs1yZMv+6mHOlU0uTGyxTZ7SxtffA5FR04rPXDH1SHN56Uf0ykCnbu1dor75GroPTN4+7XP1BQ43j127pAptOlw18vVtKEl2r5DHA8Dodbf3/mF/3f/afr/ttbKT2zWE+/tM1avmbMXa20NSlX3y47olYtQjVpwplyuU0VOdyat+iQps9KruUzQEUUl0ivfpKlWy+L0A2DwpWd59I7M7OtyWyGDwnXrv0lWrm5SNHhNk38WwOZplToMPXd2gIt/n2NRKfLVN8uQRo+JFxFDreOZLr06vQsHeF+xDrFPzBY1416W3M/eFyLPn9eYRGxuuKOl601Dhd8+qyatDxbHXpcpjM6X6TMI3s1bdI1Mk1Tiad316U3T6rlM0BF+AcEa+idb2vxjMf1w+znFRIeq0EjX1Z4VOn1XjbzWcUnnq0zul120mMNuP45Lfr0Uf33iT7yDwhRl/63qdXZA6r7FHAcjOD6zjArMDvGqlWrlJqaqnPPPVexsZ4zejVr1kzJyZV783PBdeUvNI366aFZLCz7VzJ58L9rOwTUoNZdz6jtEFCD+l8Qf/JOqDdyC07eB/XHfUNqO4LKK5j6RG2HUK6Q2yfWdghe82ok0eFw6JJLLtGOHTvUpEkTJSUlafr06R6T11R0JigAAAAAQN3jVZL4n//8R6Ghodq1a5f8/Py0dOlS3Xbbbdq2bZsCAwOrO0YAAAAA8A6DVz7zqmD3gw8+0D/+8Q/5+ZXmlP369VPnzp21YsWKag0OAAAAAFCzvBpJPHz4sLXsxR+6dOmiN998Uxs2bJBpmsrLyzvOowEAAAAA3iosLNSYMWO0YMECuVwu3XDDDXrhhRdkO2ZSHtM09corr+idd95RYWGhAgICtG3bNvn7+/v0/JWe3dRutysjI8OarMblYoY2AAAAALWsHsxuOm7cOLndbu3cuVP5+fkaMGCApkyZotGjR3v0e+6557Ro0SL98MMPiouLU0pKiux2u8/P71WSGB0drQMHDqhJkyZW25YtW/R///d/Gjx4sCTpiy++8DkYAAAAAPgry8vL0/vvv699+/bJz89PkZGRmjBhgiZOnOiRJKampur555/Xtm3bFBdXun5z48aNqyQGr9LsG264QRMnHp2yddu2bVqyZIn69OljtTG7KQAAAACUz+FwKCcnx2NzOBxl+q1bt04tW7ZUgwYNrLbu3bvrl19+kdPptNq++eYbnXfeeWrWrFmVx+pVknjfffdp1apV6tOnj4YPH67zzjtPkydPVlhYWJUHBAAAAACVZhh1cps8ebIiIyM9tsmTJ5cJPyUlRfHxnuvQxsXFyel0Kicnx2rbvHmzmjdvrrvvvlstWrRQp06d9MEHH1TJS+hVuWlYWJh++uknffnll0pLS9P48ePVoUOHKgkAAAAAAOq78ePH68EHH/RoK285QZfLJdM0y7RJntWbubm5+uabb/T+++/r7bff1saNGzVw4EA1b95c/fr18ylWryeuCQoK0o033njc/ceeCAAAAACgVGBgoFdrzMfExCgtLc2jLTU1VcHBwYqMjLTaYmNjddFFF2ngwIGSpE6dOmnkyJH6+uuvay5JPJlVq1ZV1aEAAAAAoFKMU3x20y5duigpKUmZmZmKjo6WJK1YsULdu3f3WALjzDPP1Pbt2z0eaxiGV4noyVTZK/jnmU8BAAAAABWXkJCgwYMHa8KECXI6nUpLS9OkSZM0duxYj35XX321Vq9erUWLFkkqnVz0k08+0bBhw3yO4dROswEAAACgnpk6dapSUlLUqFEjdevWTXfddZeuuOIKffTRRxozZowkKTg4WF9++aX+7//+T02bNtWNN96oqVOn6uyzz/b5+aus3BQAAAAAap1x6o+DxcbGas6cOWXaR4wYoREjRljf9+jRQ+vXr6/y5z/1X0EAAAAAQJUhSQQAAAAAWCg3BQAAAFB/2IyT98EJMZIIAAAAALCQJAIAAAAALJSbAgAAAKg3jHowu2lt4xUEAAAAAFhIEgEAAAAAFspNAQAAANQfzG7qM0YSAQAAAAAWkkQAAAAAgIVyUwAAAAD1B7Ob+oxXEAAAAABgIUkEAAAAAFgoNwUAAABQfxjMbuorRhIBAAAAABaSRAAAAACAhXJTAAAAAPWHjXEwX/EKAgAAAAAsJIkAAAAAAAvlpgAAAADqD4NxMF/xCgIAAAAALCSJAAAAAAAL5aYAAAAA6g+bUdsRnPIYSQQAAAAAWEgSAQAAAAAWyk0BAAAA1B/MbuozXkEAAAAAgIUkEQAAAABgodwUAAAAQP1hMLuprxhJBAAAAABYSBIBAAAAABaSRAAAAACAhXsSAQAAANQfNsbBfMUrCAAAAACwkCQCAAAAACyUmwIAAACoP1gCw2eMJAIAAAAALCSJAAAAAAAL5aYAAAAA6g+DcTBf8QoCAAAAACwkiQAAAAAAC+WmAAAAAOoPG+NgvuIVBAAAAABYSBIBAAAAABbKTQEAAADUH4ZR2xGc8upEkjgtYlJth4AaNGLwv2s7BNSg8fPvqu0QUIPOv+Sq2g4BNch+IKK2Q0ANylq3ubZDQE0a8kltR4BaRLkpAAAAAMBSJ0YSAQAAAKBKGIyD+YpXEAAAAABgIUkEAAAAAFgoNwUAAABQfzC7qc8YSQQAAAAAWEgSAQAAAAAWyk0BAAAA1B82xsF8xSsIAAAAALCQJAIAAAAALJSbAgAAAKg3TGY39RkjiQAAAAAAC0kiAAAAAMBCuSkAAACA+sNgHMxXvIIAAAAAAAtJIgAAAADAQrkpAAAAgPqDclOf8QoCAAAAACwkiQAAAAAAC+WmAAAAAOoN0zBqO4RTHiOJAAAAAAALSSIAAAAAwEK5KQAAAID6g9lNfcYrCAAAAACwkCQCAAAAACyUmwIAAACoP5jd1GeMJAIAAAAALCSJAAAAAAAL5aYAAAAA6g8b42C+4hUEAAAAAFhIEgEAAAAAFspNAQAAANQbJrOb+qxKRxL/8Y9/VOXhAAAAAAA1rNJJYmpqqkaNGuXR9sorr/gcEAAAAACg9lS63HTGjBlyu90ebaZp+hwQAAAAAFSawbQrvqpUkpiVlaXXX39d8+bN82g3qP8FAAAAgFNahdNs0zR1xx13aMSIEWrdunV1xAQAAAAAqCUVGknctWuXRo8erbCwMD3xxBPVFRMAAAAAVIpJuanPvH4Fw8LC1KZNG9lsNn366aeSSievCQ8PV0REhMLDw3XkyJFqCxQAAAAAUP28ThL37NmjBQsW6MCBAxozZowkqWHDhtq/f7+Sk5OVnJys2NjYagsUAAAAAFD9vE4SY2NjNWDAAC1fvlybNm3Syy+/LEmKjIxUZGSkoqKiZLMxtAsAAACgFhlG3dxOIRXO6oKDg/Xxxx/rtdde0+7du6sjJgAAAABALanU0F/jxo01atQovfrqq1UcDgAAAACgNlW6PvTGG29UcnKyR5tpmj4HBAAAAACVZRq2OrmdSiodbdOmTTVz5kyPtmHDhvkcEAAAAAD8lRUWFuquu+5SYmKimjZtqocfflhut/u4/fPz89WwYUM9//zzVfL8PqW0xjE3YFJ+CgAAAAC+GTdunNxut3bu3KktW7Zo6dKlmjJlynH7T5kyRZmZmVX2/JVKEp944gklJSVVWRAAAAAAUCVqexZTH2c3zcvL0/vvv68XXnhBfn5+ioyM1IQJEzRt2rRy+6ekpOjdd9/V5ZdfXlWvYOWSxA0bNig7O/u4+w8cOFDpgAAAAACgvnE4HMrJyfHYHA5HmX7r1q1Ty5Yt1aBBA6ute/fu+uWXX+R0Osv0Hz16tCZMmKDw8PAqi9WrJPG8885T3759rW3FihW6++67Pdpmz55t9T/nnHOqLEAAAAAAONVNnjzZWmP+j23y5Mll+qWkpCg+Pt6jLS4uTk6nUzk5OR7t//73v5WVlaWbbrqpSmP186bTs88+e9I+bdq0sb5mllMAAAAAtaKOziQ6fvx4Pfjggx5tgYGBZfq5XK4y+ZTL5ZLkOSfML7/8oqeeekqrV68uM1eMr7xKEs8///xy251Op0zTlL+/v0d7VQcJAAAAAKeywMDAcpPCY8XExCgtLc2jLTU1VcHBwYqMjJQkFRQUaNiwYXrttdfUtGnTKo/V6zT7gQceKNM2adIkvffee1UZDwAAAAD8ZXXp0kVJSUkes5WuWLFC3bt3l81Wmr4tWbJEu3bt0p133qmoqChFRUXpk08+0dNPP62LLrrI5xi8ThJnzJhhBXjPPfdIkkJDQ5Wbm+tzEAAAAABQFUzDqJObtxISEjR48GBNmDBBTqdTaWlpmjRpksaOHWv1ufTSS1VYWKisrCxru/HGG/Xkk0/q22+/9fk1rHDBrtPpVH5+viQpICCg3Bl5AAAAAACVM3XqVKWkpKhRo0bq1q2b7rrrLl1xxRX66KOPNGbMmGp/fq/uSTzug/38VFJSUlWxAAAAAMBfXmxsrObMmVOmfcSIERoxYkS5j6nK2wB9ShJtNpvcbreWL1+u8ePHyzAMmaapjIyMqooPAAAAALxXR2c3PZV4nSTm5uZq4sSJ2r17tzZt2qSJEydq7dq16ty5s9q1a+fVMhkAAAAAgLrN6yRx7NixKikpUdOmTdW0aVOVlJSoY8eOOv/889WgQYPjLpPxV2P4Byjm+jsU3KGzZNiUv/oHZc58XzpmrZOQTj0UdeUI2YKC5crJVMaMd+X4bZu1P2LAUIX3v0SGf4CK9/yqtPenyJ3HJEF1VUJcoP4+qq2aNQmW02nq3el7tHDpkTL9wkP99M3HvXQk7ei9vLP/l6KPZyZ79Bt8QbyuvLix7n7452qPHRXXZMTlSvzbjfqxz7By90d0aqcOU55SYEJDufILtXXcJKUtWmHtbzH6ZrW4Z7jswUHKWrtZm+5+TCXpmeUeC7WnyOnSS99t1Mq9h+U2TQ1q20yjz+sg2zGTD5imqY/X/6YvN+9WkdMlf5tNX9x8kfztNq3YfUhTVmxRnqP01owrz2qh27qfURung5MoKnHqxfmrtXLnAbncpgZ3aKmxF3Urc72ve3uOMgsc8rOVtp/RqIFeGdZfklTicuufC9doyfa9shmGuiTG6+9Deigi6ORT3qOG+fkr8oqbFdD2LBk2mwp/XqncudM93q9FXv83BbRq5/EwW2i4CtcsU86s9+XXJFGxoyfKlZNl7c/932cqWr9CwKnO6yTxmWeeqc446o3o626VbDbtH3+3jMAgJTw4UeH9L1Hu4m+sPn6xcYq9bYwO/eNRFSfvVlD7joq7/1Htf+QumYUFCunWW6HnXqCDzz0kd0GBYobfpQY33afUN5+vxTPD8dhs0guPd9Cns/frf4sPK7FpiN58oZN27c3Xb7vzPfqGh/kpNd2ha+/4qdxj9egSrXtvPU1BgXY5XWa5fVB7Gg48T2e88LDswcEyS5zl9rGHharbrLe18fZHlL5kpWL6dFO3WW9pWYchchxOU6NrhqjpiMu1ote1KsnOVYfXn9DZb03Uuuvur+Gzwcm8smyT3DI157ZBKixx6d6ZP2jGhp26oXNrj35TVydp9b4j+u91fRUTEqTUvELZf08gYkIC9c415ykiKECpeYW6+dOlat0gUn1bNaqNU8IJvLxwjUzT1Nejr1ZhsVN3f7hAn67epht7tPfol1NYrPduHaIm0eFljjFt+WbtSs3S7PuulL+fXc98/aP+MX+1nrnivJo6DXgp4rIRks1Q6uQHZAQEKubuCQrpPVAFyxdYfbI/fdvjMUZAoBqO/6fyly+UJNmCQ1W89zdlvMl75LrGFGu2+8qngt39+/dXVRz1ghEYpLBe/ZX5xfuS2y2zsEDZ875QWO8LPfr5N2mhkiMHVZy8W5JUtHWjTIdD/nGNJUkRAy5T1tefyp2fJ5luZc3+WCFnd5MtNKzGzwkn17VjtFwuU/9bfFiStHd/gRYuPawhFyaU6Rse7qe8/PKTC0kKDrLr3x/s0fOvJ1VbvKg8e1iIkh57RZvuevS4fRpff4my125W+pKVkqSM5WuV/v0aNbruYklSy9E36ddn/qWSzGzJ7VbSk68p7pJ+8o+OrJFzgHcKip36Zus+je7TQX42m8ID/XVr97b6estej36ZBQ69tyZJEwd3U0xIkCSpYViwNfrULj5aEUEBVvuZ8dE6kldYsyeDkyooLtHXG3dqzICupdc7KEB39Dlbczb8VqZvdqFD4b9f02NtP5SuC85oruAAf/nZbBpy1mnampJe3eGjgoyAQAV3O08530wvfb9WVKi8xXMU0v3EVXGhfS+WY/tGuVIPSpJsIWEyC/NP+BjgVFXpJDE/P1/9+/evylhOeQGJreRMOyx3/tGyUMfuHQpo3Lx0uOmPtl+3yBYSqqD2HSVJod3Pk7sgT8X790g2mwJbtPIoPXXn5cqZnir/Jok1di7wXoe2Edq8LcejbeuOXLVpWTapDw/zV+4JksSlP6ZpxRreUNRVh75coCNzvzthn+ienZT543qPtuw1mxTR8QwZdrsiu3ZQxp/2l6RnqnBvisI7nF4tMaNyth3JVJPIUEUFHy0T7JAQo9/Sc+R0u622H3YfVOcmsUoIDznh8dymqVV7D2tvZp4ubNOk2uJG5WxNSVeTqDBF/Z7oS9KZTWK180imx/UucblVVOJU2HGSxEFnttS8zbuUkV+owuISfb42SRefdVq1x4+K8W/aUq6MVJkFeVZbyb6d8kto6vF+7c+MgECF9BmovG9nHW0LDpW7sKDa4wVqg1flpvv27SvTVlBQIKfTqeTkZJlm2bK45s2b+x7dKcYvKsajLl2SXLnZMvz8ZAsOKR0ZlOQuyFfGjHcVP/YpmcUOGX5+OvjCBMnllD0yWrLZytx/6MrNlj2sbGkLal9sgwCPewwlKTO7RBHhZX+9IsL81LZVuGa+20O5eU59tyJVH89MltNJaWl9EdQoTunfeZYTO1LTFdW9owIaxsiw28vcf+hIzVBAg6gajBInk5pXpJgQz/vIooMD5XKbyi92KvL3JOG3tBwlhAfruUXrtXLvEYUH+mt4l9a6tP3RD/VGfrJEv6XlKCIoQE8O7KroEO5Pq2tScwvUICzYoy0mNFhOt6l8R4kif/+wIKfQIcMwdOnrM+Vns6lrYrzu699ZsWGlHxJcdGYLLdq2Vxe9/JnsNkOnJ8Ro0lWUmtY1tshoufOyPdrceTky7H4yAoPLHR0M7n6+SnYnyZWRevQ4IWEKOrOrAh9/Q67cbBWuWaaCFb4vYg7fmcxu6jOvksTevXtby1scq1evXtbXf/QxDEObN29WZGTZ8imHwyGHw/MNtcPlUqDdXtHY6x6bTTqmBtr444f0T69dQMs2ihl2mw4+O07F+3YpqF1Hxd3zdx16YbxMt6vcQxuGTSKPqJNsNkPGMRMb2I/zt+m7Falasrz0P5hmjYM1fkxbhYX66V/v7qruMFFDDLv92D8DMuz20r+Nx/nBMOy2cv++ova4TbPMn1z379foz5c3v9ipH3Yd1NODu2nChZ21IzVb9325QgnhIerWrKEk6cMb+8vlNrX5YIaeWrhW9/Rqr0Ftm9XMicArbtMs8zvoNktHEP98vRuEBWvd4zfJMAxlFRTpjcXrNXr6Yn18x6UyDEMvL1gjmyEt/b8b5G+36bVF6/TIzO+tiW1QN5S+NzvmD/VxRhD/ENLjAuXM/sCjLX/pN8r/7mtJkl+TFooeMUqSoYIVC6swWqB2eJVmJycna9++fUpOTj7u9uuvv2ratGlW3/ISREmaPHmyIiMjPba3Nv5apSdVW9z5ebKHR3i02cIj5XY4PMoRIi4cqtzv5ql4X2liULRtowp+XqWwvgN/H200ytx/aAuPkCub2Q9r2+f/7WFtzz92piQpJ9epyAjPz1uiIv2Vnllc5vF/fg+SnFKof727U/37NKzWmFGzijOyFRAb7dEWEBsjx+FUlWTmSIZR5v7D0v1pNRkmTiIiKEBZhcdUCBQ6FOhnV1igv9UWFRygnonxOjcxXoZhqG1clC5u10zf7zro8Vi7zVCnJg10Z492mrGBD4XqmojgQGUVHHO98x0K8rOXKS3940PBqJAgTbikp3anZutAVp4KS5yasWa7JlxyrsKDAhTk76eHBp2jtXsOaW+65y0JqF3ugnzZQj2rs2xh4TKLHTKLypaP+jdtKVtImIp3bvPc8af/1J0H9ih3wUwFdexRLTEDNc3rsdgdO3bokUcesb7Py8vz+NQtLy9Pjz/++EmPM378eGVnZ3ts93RsU8Gw66bivTvlH99EtpBQqy2odTsV79nh8YfE8POT6TpmxNDtlmH3k1nsUMnhAwpsdXSKdHtktOwRUSrev7vazwEndu0dP1nbI89ukSQl/Zars87wfNN/VrtIbdl+8jcFNpuhkhJGkOqT7PVbFN2zs0dbdK8uylq1Qa6CQuUn7Vb0uUf3ByY0VGB8A+Vs3F7ToeIEzoiL0t7MPOUUHf2wZ2NKujokRHssidCqQYTyi0s8HmsYhgL9yq+O8bfbFHScfag97RrFaE96tnL+9MHAhuTDOrNJbJklMP7MVOkSKP6/VwO4TdOa2VaSbIYhQ1LJsf/no1aVHNgtv7hGMoKPvl8LaNFWxft2llmyTJKCu/ZR0eY1Jz+wzSZxresGw1Y3t1OI19Hm5uZq06ZNkqTbb79djRo1Unx8vBYvXixJCgsLU27uydfxCwwMVEREhMdWL0pNJblyslT4y3pFXTVSstlkCwtX5CXXKOfbrz365a9Zroj+l8geEytJCmh+mkJ79lPB+h8lSXnfL1TU0OtlCw6V7H6Kvmqkcn/4VmZx2ZEp1L4Va9IVGxOggf3iJEltW4epT/cG+nrhwTJ9258ervCw0lHHmCh/3XPLaVrw3eEajRfVK2X6V4rtf64a9OspSWo4uK/C2rbUwS/mS5L2TZ2hNo+Pkl9kuAx/f7V97kHtm/q53IVFtRk2jhEbGqReifGasmKLnG63Mgsdend1UpnlL/q3aaIthzL1097SdVF3p+do/vZkDTy9qSRpxoadVhKZkp2vd1cn6YoOLWr0XHBysWEh6t26id5YvL70ehcUaeoPmzW8p+fyF8kZOdqbXnovW7HTpRf/t1odmjZUfESoQgL81etPx3Cbpt5etkHxEaFqGcvsxXWJOzdbju0bFX7xMMlmkxEarrALL1f+D/PL7R94Rkc5ft1Spj3gtDNkBJTer2pvEK/wi65U4bofqjV2oKZ4vU7iH+bOnaudO3cqLS1Ne/bs0WWXXaakpCQFBgaWudfwryjt/TcUe/P9avbyezIdRcpeMFsFG35SaM/zFdiijTI+/a8K1v0oW0io4sc+JVtgoNz5eUp7/w05du2QJOUs+lr2qBg1ee5NmW63Cjb8pMyZ79fymeF4HA63/v7ML/q/+0/X/be3UnpmsZ5+aZtS00uT+jF3tdLWpFx9u+yIWrUI1aQJZ8rlNlXkcGveokOaPiu5ls8Avmpy42WK7HaWtj74nIoOHNb64Q+qwxtPyj8mUgU792rtlffIVVC67MHu1z9QUON49du6QKbTpcNfL1bShJdq+QxQnscHdtEzC9dr0L/nKdjfTyO7ttEFrRtr3rZ92nIoUw9f0FFBfnb9Y2hPTV7yszIXOhQdHKgnLuqiNg1Lk4Lf0rJ15bSFCvCzKzIoQLd1b6uBbZvW8pmhPE9e1ltPf7VCF708Q0H+frq5Vwf1PyNRczft1C8H0vT3IT2UXVis8TOXqcjpUqCfXT1aNtJL1/azjvHclefplYVrddkbX8o0TbVvHKvXb7xQ9pPc74aal/XZfxR13Z2Ke/JNmcUO5S+dK8cvaxXcpbf8m7VSzpzS+w+NoBD5xTVWyYGy1VwBrc9U1E1jZJYUy3QUKu+7b1S4liQR9YNhejFbwqxZs5SUlKRly5bp7LPPVufOnXX99ddLkq688kpdeOGFiouL08MPP6y9e/ee5Ghl7bnj8opHjlPWiMMP1nYIqEHj599V2yGgBp3/xlW1HQJqkD0i4uSdUG9krdtc2yGgBjV6+ZPaDqHSMjcuq+0QyhXd8cRrcdYlXo0kfvXVVzp48KBsNpuKiooUGnq0hjskJETz5s1TZGSknM7jr/8GAAAAAKj7vKp/mDZtmp577jmZpql27dpZ9yE6nU6tXr1aX3zxhaZPny4/vwpXrwIAAAAA6pAKZXWGYWjkyJHq2rWrrrnmGu3du1dXX321QkJCrP0AAAAAUFvMU2wm0bqoQkmiaZoKDQ3VqlWrNHfuXMXFxemiiy6y9pMkAgAAAMCpzesksXPnzpo5c6YkKSoqSsOHDy/T5667mKACAAAAAE5lXieJNpvNKis9nvHjx/scEAAAAABUGtWNPqtUwe7kyZP13//+t6pjAQAAAADUMq+SRLfb7bG5XC45nU6Ptj/7z3/+Uy3BAgAAAACql1dJop+fn/z9/a3tiSee0L333it/f39r3xNPPGH1f/TRR6stYAAAAAA4HtOw1cntVOLVPYnHjhSejGmalQoGAAAAAFC7fEppHQ6HMjIyyrSzFAYAAAAAnJoqtE7isZ5//nkVFhbq+eefr6p4AAAAAKDSTDFg5atKJ4kffvihvvrqKy1btqwq4wEAAAAA1CKvk8QjR47I7XZrx44deuedd7R7927Nnz9fYWFh1RkfAAAAAKAGeZ0k9ujRQy6XSykpKYqOjta3336rhg0bSiqdqCY5Odn6uqIT3QAAAABAVTjVZhKti7xOEnfv3i1JKigo0PTp03X11Vdr4sSJGj58uLKystSjRw8ZhiHTNBUQEFBtAQMAAAAAqk+F70kMCQnR7bffriFDhmjw4MHy9/fXddddp4MHD1ZHfAAAAACAGlTpsdjGjRtr9uzZmjRpUlXGAwAAAACVZxh1czuF+FSwe9ppp2nVqlVVFQsAAAAAoJb5fFdnUFBQmbZ9+/b5elgAAAAAQC3w6p7EMWPGaM2aNeXu+/HHH9WrVy9JpSWoX3zxhXr27KmUlJSqixIAAAAAvGD6Pg72l+dVknj77bfrqquuOu7+HTt2aO7cubrhhhsklS6DAQAAAAA49XiVJJ599tkn3B8QEKAePXpUSUAAAAAAgNpToSUwVqxYoVmzZik+Pl733HOPwsLCqisuAAAAAKgw8xSbSbQu8rpg9+uvv9bNN9+shIQEpaSkqF+/fnI6ndUZGwAAAACghnk9kvjss89q7ty5atu2rSRp4sSJmj59ukaOHFltwQEAAAAAapbXSWJaWpqVIEpS3759tWDBgnL7GgzxAgAAAKgFpsHspr7y+hW02+1yOBzW9wcPHlSDBg0kHZ3N9ODBg+rfv78yMjKqOEwAAAAAQE3weiTxiiuu0JgxY/Tiiy8qOTlZL7zwgmbOnClJ+vLLLyVJ8+fPr54oAQAAAAA1wusk8emnn9a9996rZs2aKS4uTi+++KJatWolSTr33HMlSeeff371RAkAAAAAXjDFrW++8jpJDA4O1rRp0zRt2rTqjAcAAAAAUIu4qxMAAAAAYPF6JBEAAAAA6jpmN/UdryAAAAAAwEKSCAAAAACwUG4KAAAAoN4wDWY39RUjiQAAAAAAC0kiAAAAAMBCuSkAAACAesMU5aa+YiQRAAAAAGAhSQQAAAAAWCg3BQAAAFBvmAbjYL7iFQQAAAAAWEgSAQAAAAAWyk0BAAAA1BvMbuo7RhIBAAAAABaSRAAAAACAhXJTAAAAAPUGs5v6jlcQAAAAAGAhSQQAAAAAWCg3BQAAAFBvMLup7xhJBAAAAABYSBIBAAAAABbKTQEAAADUG8xu6jteQQAAAACAhSQRAAAAAGCh3BQAAABAvcHspr5jJBEAAAAAYCFJBAAAAABY6kS5aUSLhNoOATWoddMzajsE1KDzL7mqtkNADVp2/5e1HQJq0IWzH6jtEFCDont2re0QAK+YBuWmvmIkEQAAAABgIUkEAAAAAFjqRLkpAAAAAFQF06Tc1FeMJAIAAAAALCSJAAAAAAAL5aYAAAAA6g2TcTCf8QoCAAAAACwkiQAAAAAAC+WmAAAAAOoNU8xu6itGEgEAAAAAFpJEAAAAAICFclMAAAAA9Qblpr5jJBEAAAAAYCFJBAAAAABYKDcFAAAAUG9Qbuo7RhIBAAAAABaSRAAAAACAhXJTAAAAAPUG5aa+YyQRAAAAAOqQwsJC3XXXXUpMTFTTpk318MMPy+12e/QpKSnRxIkTddZZZ6lZs2Y677zztGHDhip5fpJEAAAAAKhDxo0bJ7fbrZ07d2rLli1aunSppkyZ4tFnx44dysrK0qpVq5ScnKwRI0Zo6NChKikp8fn5SRIBAAAA1BumadTJzVt5eXl6//339cILL8jPz0+RkZGaMGGCpk2b5tHvzDPP1D//+U+FhoZKku6++27l5+fr119/9fk15J5EAAAAAKhmDodDDofDoy0wMFCBgYEebevWrVPLli3VoEEDq6179+765Zdf5HQ65edXfgpXUFCggoICRUZG+hwrI4kAAAAAUM0mT56syMhIj23y5Mll+qWkpCg+Pt6jLS4uTk6nUzk5Occ9/mOPPaZ+/fqpSZMmPsfKSCIAAACAeqOuzm46fvx4Pfjggx5tx44iSpLL5ZJpmmXaJMkwyp5bYWGh7rvvPm3cuFHz58+vklgZSQQAAACAahYYGKiIiAiPrbwkMSYmRmlpaR5tqampCg4OLlNKunPnTnXr1k12u10rVqxQw4YNqyRWkkQAAAAAqCO6dOmipKQkZWZmWm0rVqxQ9+7dZbMdTd8yMzPVv39/jR07Vv/5z38UFBRUZTGQJAIAAACoN0wZdXLzVkJCggYPHqwJEybI6XQqLS1NkyZN0tixYz36ff7552rfvr3uvPPOKn4FSRIBAAAAoE6ZOnWqUlJS1KhRI3Xr1k133XWXrrjiCn300UcaM2aMJOm3337TihUr1KJFC4/trbfe8vn5mbgGAAAAAOqQ2NhYzZkzp0z7iBEjNGLECEnSiy++qBdffLFanp8kEQAAAEC9UVdnNz2VUG4KAAAAALCQJAIAAAAALJSbAgAAAKg3TJNyU18xkggAAAAAsJAkAgAAAAAslJsCAAAAqDfczG7qM0YSAQAAAAAWkkQAAAAAgIVyUwAAAAD1hkm5qc8YSQQAAAAAWEgSAQAAAAAWyk0BAAAA1BumSbmprxhJBAAAAABYSBIBAAAAABbKTQEAAADUG8xu6jtGEgEAAAAAlkoliW+99ZZmzJhR1bEAAAAAAGpZpZLEzMxMZWdnH3f/ggULKh0QAAAAAFSWaRp1cjuVeHVPYrNmzWQYR08sJydHNptNzz77rNU2ZswYjRs3TpI0cuRIHTlypIpDBQAAAABUN6+SxOXLl5+0T1RUlPW1aZqVDggAAAAAUHu8ShITExPLbTdNU8XFxQoMDPRo//OoIwAAAADUFGY39Z1Ps5u++eabevLJJ6sqFgAAAABALav0OomLFy/WlClTtGzZsqqMBwAAAABQiyqcJO7bt0/vvPOOZs+era+++kpxcXHVERcAAAAAVNipNpNoXeR1khgcHGzdg9igQQP9+OOPatOmTXXGBgAAAACoYV7fk1hYWKiCggJt2bJFf/vb3zRgwAAtXbpUkpSeni6bzSa73S6bzab09PTqihcAAAAAUI0qNHGNzWZTu3bt9Mwzz2jevHm6/fbbtXTpUjVo0MBKIv/4FwAAAABqmruObqeSSk9cc+aZZ+qLL77QjTfeqG3btpVZBuMvy89fIQOHyb9VexmGTY4ta1S4+EtJR9eODL3sFvk19yzVtYWEy7HxRxUs+NRqszdpqbBLb1LOR6/IzM+pqTNAJcRG2XTL0AglNPCTy21q9tJ8rdxUVKZfi8Z+GnlxuMJDbbLbDK3dWqQZ3+bJ/ftfjiG9Q9S3c7AC/A0VFLk1c0m+NiQ5avhscDxFTpde+m6jVu49LLdpalDbZhp9XgfZjln2xzRNfbz+N325ebeKnC7522z64uaL5G+3acXuQ5qyYovyHCWSpCvPaqHbup9RG6cDLzUZcbkS/3ajfuwzrNz9EZ3aqcOUpxSY0FCu/EJtHTdJaYtWWPtbjL5ZLe4ZLntwkLLWbtamux9TSXpmTYUPLxUVO/Xi7O/0Y9JeudymhnRuq7GXniebzfP3+9p/fKjM/EL52+2SpLZNGurV2y6TJO1Pz9JLc77XrsMZKiopUd/2p+mhy85XUECl326hmhSVOPXi3B/146/75TJNDTm7lcYO7FH2ek/5Qpn5RfK3l46rtG0Uq1eHD7T2p+UW6B/zVmrDvkNyuU1d0rG1Hhjcs0bPBagOPv3V6ty5s1VyilIhA66RDEPZUx6TERCg8OEPyH1OPznWfGf1yf/qPc8H+Qcq6t5nVPR7H1t0rEIG3yh7TJzs0Q1rMHpUhmFIY26I0oKVBVq+oUiNYu169LYYHTji1L5DTo++jmJTb8zIVlauWyFBhh6+KVr9uwVr0epCSdKu/SVauLJALrd0eqK/HhoRrQf+mar8QrO8p0YNe2XZJrllas5tg1RY4tK9M3/QjA07dUPn1h79pq5O0up9R/Tf6/oqJiRIqXmFsv/+xiMmJFDvXHOeIoIClJpXqJs/XarWDSLVt1Wj2jglnEDDgefpjBcelj04WGaJs9w+9rBQdZv1tjbe/ojSl6xUTJ9u6jbrLS3rMESOw2lqdM0QNR1xuVb0ulYl2bnq8PoTOvutiVp33f01fDY4mZe/Wia3KX0z4TYVFpfo7rdnavryDRret7NHv5xCh967f5iaNogsc4wFG3boyh4ddP6Zpym/qFgPvve13l64UmMvPa+mTgNeevl/q+Q2TX3z4PUqLHHq7mlzNf2nLRp+bgePfjmFDr1352VqGhNR5hiOEqfumjZXl3c5XZOuvUB2m02Hs/Nq6hSAalWpdRKdTqdyc3MlSfHx8VUa0CnNP1CBZ5+rwiVfSqZbpqNIhSv+p8COvU74sKAeF6pk5y9yZxyWJBkBwSpJ+lnZ7zxdE1HDR+1PC5DbLS3fUDpyeDDNpR83Fal3x6AyfQ+muZSVWzpsWFBkKmlPsaIj7Nb+pL0lcv0+qrhjb4mKS0xFhPq0nCmqSEGxU99s3afRfTrIz2ZTeKC/bu3eVl9v2evRL7PAoffWJGni4G6KCSn9GWgYFmyNNraLj1ZEUIDVfmZ8tI7kFdbsycAr9rAQJT32ijbd9ehx+zS+/hJlr92s9CUrJUkZy9cq/fs1anTdxZKklqNv0q/P/EslmdmS262kJ19T3CX95B9dNsFA7SlwFOurtVs19tI+8rPbFB4cqNsv7K45a7aU6ZtdUKSI4PKrp26/sLvOP/M0SVJoUIBu6NNJq39NrtbYUXEFjhJ99fMOjR3Uo/R6BwXo9vM7ac76pDJ9swsdx73eM9duV1xEqG7u01F2W+n/1fGRYdUaO7xjmkad3E4llXr3uXjxYt13331VHcspz69Rc7my0mQW5lttzpQ9sjdsIhnHean9AxR0zgUqXD7XanIdTpZj/Q+Ss6S6Q0YVaN3UX78me16r3QdK1DzB/4SPa9nYT2e2CtDyDWUTBH8/aWDPEO06UKKDaa4qjReVs+1IpppEhirqT28WOiTE6Lf0HDndR+80+GH3QXVuEquE8JATHs9tmlq197D2ZubpwjZNqi1uVN6hLxfoyNzvTtgnumcnZf643qMte80mRXQ8Q4bdrsiuHZTxp/0l6Zkq3Jui8A6nV0vMqJytyUfUJCZSUaHBVluH5gnaeTBdTtfR3+8Sl0tFJSUKC/LuFpuMvEKFHyfBQO3ZmpKqJtHhigo5+mFuh6Zx2nk445jr7VZRiVNhgQHlHmfRlt26omvbao8XqA0nLTctKSnRwYMHPdoOHz6s/Px8JScnyzRN2Ww2NW3aVNu3b5cknXHGX/P+Glt4lMz8XI82Mz9Hht0uIzBIZlHZCX0CO/aWM3mn3FnMCHuqigq3KTPH83bknHy3wkLK/8To/mGR6tAqUC63qY/m5XokgQ2j7XrklmhFR9i0J8Wpt77IrtbY4b3UvCLFhHi+2YsOLr2O+cVORf4+OvhbWo4SwoP13KL1Wrn3iMID/TW8S2td2j7RetzIT5bot7QcRQQF6MmBXRUdwpvIU1VQozilf/eTR5sjNV1R3TsqoGGMDLu9zP2HjtQMBTSIqsEocTKpOXlqcMwHOzHhwXK63covKlZkaGkykVNQJEOGLpn0rvzsNnU9ralGDeml2IjQMsfMyi/UtCVrdO+QE1cToeal5hSoQViwR1tMaLCcblP5jmJF/p485hT+fr3/+Wnp9W6RoFEDzlHs7z8rvx7OkKPEqZv/PUdHcvLVKi5aD118rlrERtX0KQFV7qRJ4pYtW3TllVeWu69v376SpMjISL300ksaNmyYTNPUp59+qoEDB5b7GIfDIYfDcyIOh9OlQD97uf1PKYZNOjYvON4I4u8CO/dWwcLPqi8mVDubzShz3W02yTzObYRvzMiWYUhN4vx022URigy36X8rSj9ASM10adwrafL3k7q2C9Ljd8TouakZOpzBaGJtc5umjr2k7t8v8p8vf36xUz/sOqinB3fThAs7a0dqtu77coUSwkPUrVnpPcYf3thfLrepzQcz9NTCtbqnV3sNatusZk4EVcqw28v8/ht2u0zTlGEv/++/YbfJPN4fCNQKl9ss8zfb7f799/tP17dBeKjWvzRGhmEoK79Qr89dodFT5+jjsTfI+FPHHSmpeuj9uRrUua2GdGakqa5xmeVd79IPe/98HRuEhWj9xDtKr3dBkV5fuFqjP1qgj/92hQzDUIGjWN9u2a2XbrhI0SFB+mDFJt3/4QJ9Ofpaa6Ib1A6zzBtyVNRJf4I7deqk3bt3H3dbvny5li5dqtdee01z5szRF198oXfeeee4x5s8ebIiIyM9tle//7lKT6q2mIX5MoI9a9FtoeEyS4plFpUtKbQ3SpQtOEzOvTtqKkT46KWxsdY25oYoSVJ+oVvhIZ6/SuEhNmXnHX+yY9OU9h926tMFubqoR9myxBKntGpzkTYkOdS7U9l7G1HzIoIClFXo+QFXZqFDgX52hQUeLS2OCg5Qz8R4nZsYL8Mw1DYuShe3a6bvd3lWZNhthjo1aaA7e7TTjA27auQcUPWKM7IVEBvt0RYQGyPH4VSVZOZIhlHm/sPS/Wk1GSZOIjIkSFn5nv9PZ+YVKsjfr0xp6R9JRFRosB69pr92Hc7QgYyjVR+zV2/RPe98qdEX99YoRhHrpMjgQGUVeM5AnplfpCB/e5nSUut6hwTp0cv6aFdqpg5k5lptI3udpYbhIfKz23TreR2VU1ikPalZNXIeQHXy+mOO3r17W1/v2rVL+/fvlyRNnz5dy5Yt09atW9W7d2+df/752rRp03GPM378eGVnZ3tsY4+ZOexU5Ty0T/YG8TKCjr7p92vaSs6U3VKZMQgpsEMPFW+vHwnyX8VDr6ZZ22vTsyRJe1JK1LqZ5/2HbZr7a+f+k99TWuIyVVxy/BGFk+1HzTkjLkp7M/OUU1RstW1MSVeHhGiPJTBaNYhQfrHntTcM47jVEv52m4LqQyXFX1T2+i2K7un5f1h0ry7KWrVBroJC5SftVvS5R/cHJjRUYHwD5WzcXtOh4gTaNY3TniOZyvlT4vDznhR1aJ5QZkmEPzPN0iVv/lgO49uNO/TOwlWaNmqYBnRsc9zHoXa1axyrPWlZyvnTB38/7zukDk3ivLzepW+fW8XFqOBPf+8Nw5AhQwH8TUc94HWSuG/fPknS559/rgEDBqhnz576/vvvFRYWpry8PLndbhmGIfvvZTbHExgYqIiICI+tXpSaqvT+w5KdWxR8wRWSYZMRHKqg3kNU9NPicvv7tzpTJXt4o3Cq27DDoahwm849u3TEr0VjP3VqG6hl68uOHvftEmzdqxgeYuiaC8O0bF1pv6hwm3p0CNLvE6Tp9ER/dWkbqNVbWCexLogNDVKvxHhNWbFFTrdbmYUOvbs6qczyF/3bNNGWQ5n6ae8RSdLu9BzN356sgac3lSTN2LDTSiJTsvP17uokXdGhRY2eC6pOyvSvFNv/XDXoV7ouWsPBfRXWtqUOfjFfkrRv6gy1eXyU/CLDZfj7q+1zD2rf1M/lLiy7jipqT2xEqHqfkajX562Q0+VWZl6hpi5aXWb5i+S0LO05UnqPabHTqRdnL1WH5gmKjwqXJH24bL3GXNJHzRtG1fQpoAJiw0PUu00zvf7t6tLrnV+kqcs2aHivszz6JafnaE9aliSp2OnSi/N+VIemcdYMptf1aKf/LP3ZGpV8f/lGNWsQoeYNyi6XgZpV27OY1ofZTb1eJ/GP4fZXX31Va9as0fbt2/Xqq69q6NChKiws9EgMDePUehGqUv43Hyj00psUNfZFmSUOFa36ViU7NiqgQw/5NU607j80AoNlj02Q69C+Wo4YvioukV79JEu3XhahGwaFKzvPpXdmZluT2QwfEq5d+0u0cnORosNtmvi3BjJNqdBh6ru1BVr8+xqJTpepvl2CNHxIuIocbh3JdOnV6Vk6wv2IdcbjA7vomYXrNejf8xTs76eRXdvogtaNNW/bPm05lKmHL+ioID+7/jG0pyYv+VmZCx2KDg7UExd1UZuGpSWHv6Vl68ppCxXgZ1dkUIBu695WA9s2reUzQ0U0ufEyRXY7S1sffE5FBw5r/fAH1eGNJ+UfE6mCnXu19sp75Coo/b3e/foHCmocr35bF8h0unT468VKmvBSLZ8ByvPUsIF6asZCDXjq3woO8NdN/bqq/1mt9c3abdqSfEh/v/ICZRcU6ZEP56moxKlAfz/1aNNcL99yqXWMfWlZemnOMr32zXKPY3/8wA2KCTvxjMeoWU9deb6emrVMA174SMEBfrqpz9nq376Fvtnwq7YcSNXfL+ml7MIiPfLZktLr7WdXj1ZN9PINF1nHGHDmadqblq1rp8yUn82m9k1i9c8bB/6l3wej/jDMk9w9v2XLFn300Uf6+OOPtW/fPnXu3Fk///yziouLlZiYqF69eumCCy7QK6+8op07d8rtdqtt27b69ddfvQ4i49m7fT4RnDoedE6s7RBQg6YkvFrbIaAGLbv/y9oOATXowtkP1HYIqEkF+Sfvg3oj6NpxtR1Cpa3YmlfbIZSrd/tTZx3Nk44k+vv7KzKy7KK/fyx9ERwcrJKSEp1xxhlatWqVSkpKdNZZZ5VzJAAAAACoXsxu6ruT3pN4+umn65FHHrG+Dw4O1pEjR7Rq1Sr17t1b1113nZxOp0aPHq2hQ4fqqquu0t13MzIIAAAAAKcir+9J/MODDz6ozp07y+12a+bMmcrKypLT6dSgQYO0bNkymaapM888szpiBQAAAABUM6+TxLZtSxeDveaaa9SrVy/5+/urYcOGmj9/vkpKSmfqa9++ffVECQAAAABecLN6mM+8ThK//fZb6+vGjRtr3bp1crlc6t27t84555xqCQ4AAAAAULO8XifxWG+//bbWr1+v8PBwNWjQoCpjAgAAAADUEq9GEvftK7uWX35+vo4cOVLuPklq3ry5b5EBAAAAQAUxu6nvvEoSe/fuLcMwdOySij/88IMef/zxMv0Nw9DmzZvLXToDAAAAAFB3eZUkJicnV3ccAAAAAIA6oMJLYEiSy+VSRkaGGjZsWNXxAAAAAEClmSblpr6q0MQ1H374oc466yxFRkaqY8eOCgsL0wUXXKDvv/++uuIDAAAAANQgr5PE559/Xv/85z/11ltvKS8vTykpKcrKytLf/vY3XX/99Vq0aFF1xgkAAAAAqAFel5tOmTJFa9asUaNGjY4+2M9Pw4YNU2hoqN544w0NGDCgWoIEAAAAAG8cM9cmKsHrkcTCwkLFxcWVuy8xMVHZ2dlVFhQAAAAAoHZ4nST27dtXzzzzTJn2kpISPfnkkxo0aFCVBgYAAAAAqHlel5u+9dZbuv7669WuXTv169dPMTExOnjwoBYsWKDBgwfr4Ycfrs44AQAAAOCk3GJ2U195nSQmJCRo6dKlWrNmjTZt2qT09HS1a9dOjz76qFq1alWdMQIAAAAAakiF10k855xzdM4551RHLAAAAACAWlbhJBEAAAAA6irTpNzUV15PXAMAAAAAqP9IEgEAAAAAFspNAQAAANQbplnbEZz6GEkEAAAAAFhIEgEAAAAAFspNAQAAANQbppjd1FeMJAIAAAAALCSJAAAAAAAL5aYAAAAA6g03s5v6jJFEAAAAAICFJBEAAAAAYKHcFAAAAEC9YZrMbuorRhIBAAAAABaSRAAAAACAhXJTAAAAAPWGyeymPmMkEQAAAABgIUkEAAAAAFgoNwUAAABQb7jF7Ka+YiQRAAAAAGAhSQQAAAAAWCg3BQAAAFBvMLup7xhJBAAAAABYSBIBAAAAABbKTQEAAADUG6bJ7Ka+YiQRAAAAAGAhSQQAAAAAWCg3BQAAAFBvuJnd1GeMJAIAAAAALCSJAAAAAAAL5aYAAAAA6g2TclOfMZIIAAAAALCQJAIAAAAALJSbAgAAAKg3TBm1HcIpj5FEAAAAAKhDCgsLdddddykxMVFNmzbVww8/LLfbXabfzz//rJ49eyoxMVHt27fXwoULq+T5SRIBAAAAoA4ZN26c3G63du7cqS1btmjp0qWaMmWKR5/c3FwNHTpUzz77rPbu3au3335b1113nQ4dOuTz85MkAgAAAKg33Gbd3LyVl5en999/Xy+88IL8/PwUGRmpCRMmaNq0aR79pk+frnPOOUcDBgyQJPXt21fnn3++ZsyY4fNrSJIIAAAAAHXEunXr1LJlSzVo0MBq6969u3755Rc5nU6rbeXKlerdu7fHY7t3764NGzb4HANJIgAAAABUM4fDoZycHI/N4XCU6ZeSkqL4+HiPtri4ODmdTuXk5Jy0X3p6us+xkiQCAAAAqDdMs25ukydPVmRkpMc2efLkMvG7XC6ZplmmTZIMwzhpvz/3qSyWwAAAAACAajZ+/Hg9+OCDHm2BgYFl+sXExCgtLc2jLTU1VcHBwYqMjDxpv4SEBJ9jrRNJYkiXrrUdAmpQ/9D4k3dCvWE/EFHbIaAGXTj7gdoOATVo8RWv1HYIqEHtR7at7RBQg1peO662Q6h3AgMDy00Kj9WlSxclJSUpMzNT0dHRkqQVK1aoe/fustmOFoJ27dpVP/74o0fiuWLFCl1//fU+x0q5KQAAAIB6o7bLSo+3eSshIUGDBw/WhAkT5HQ6lZaWpkmTJmns2LEe/YYPH67FixdryZIlkqR58+Zp+/btuvbaa31+DUkSAQAAAKAOmTp1qlJSUtSoUSN169ZNd911l6644gp99NFHGjNmjCSpadOm+vTTT3XvvfcqLi5Ozz77rL7++muFhob6/Px1otwUAAAAAFAqNjZWc+bMKdM+YsQIjRgxwvp+0KBB2r59e5U/P0kiAAAAgHrDbfo+u+dfHeWmAAAAAAALSSIAAAAAwEK5KQAAAIB6oyIziaJ8jCQCAAAAACwkiQAAAAAAC+WmAAAAAOoNyk19x0giAAAAAMBCkggAAAAAsFBuCgAAAKDecFNu6jNGEgEAAAAAFpJEAAAAAICFclMAAAAA9YZpGrUdwimPkUQAAAAAgIUkEQAAAABgodwUAAAAQL1hMrupzxhJBAAAAABYSBIBAAAAABbKTQEAAADUG27KTX3GSCIAAAAAwEKSCAAAAACwUG4KAAAAoN5gdlPfMZIIAAAAALCQJAIAAAAALJSbAgAAAKg3KDf1HSOJAAAAAAALSSIAAAAAwEK5KQAAAIB6w025qc8YSQQAAAAAWEgSAQAAAAAWyk0BAAAA1BvMbuo7RhIBAAAAABaSRAAAAACAhXJTAAAAAPWG213bEZz6GEkEAAAAAFhIEgEAAAAAFspNAQAAANQbzG7qO0YSAQAAAAAWkkQAAAAAgIVyUwAAAAD1BuWmvmMkEQAAAABgIUkEAAAAAFgoNwUAAABQb7gpN/UZI4kAAAAAAAtJIgAAAADAQrkpAAAAgHrDrLPTmxq1HYDXGEkEAAAAAFhIEgEAAAAAFspNAQAAANQbdbba9BTCSCIAAAAAwEKSCAAAAACwUG4KAAAAoN5wu2s7glOfV0liy5YtZRjeTdlqmqYMw9DPP/+syMhIn4IDAAAAANQsr5LERYsWVfjAJIgAAAAAcOrxKkls1aqVJk6cWKEDP/HEE5UK6FRXVFyiF2d9px+T9sjlNjWkyxkae2lf2WyeI7HX/uMDZeYXyt9Welto26ZxevW2yz36bNqToic/XaD/3HudYiNCa+wcUHFZafs178PHlX54j+x2P503dJTO6nl5uX23rP5GP3zzLxUX5SsmLlGX3jJJUbHN/r+9+w6Polz7OP7b3fSeEEIgAUITQaR3kA6HIhaOjXIURI8dlIMFQUFUQAQ9oK+9gAWFI6AUQVBEuhDpoUlJQEIJJCSkbZLdff8IjCwJsCGV8P1c114XefaZmXvYzGTveZ65J0+/H796WYf3btSjry4t7vDhoszsHE1eulHrDxyVze5QzwY19HT35jJfNNPing9+UFK6VW7njvsbK1fQ2/d2kSRl2+x6a9kmrdgTJ7PJpKbVK+n5Xq0U4OVZ4vuDy8vMytHk73/Vur1xuefzJnX19K235HM+/zL3fG6xSJLqRlTUfx+8TZL01+kzmvLDKh08kajM7Gx1qF9TI2/rKC8P7vYoqyIG3a7qjw7Quvb35vt+QON6avDuOHmGV5QtLUO7/jNBp35ea7wfNewBRT02UBZvL52J3qHtj4xR9umkkgofLjK5eyhkwMPyuamJZDYr9fdVSvpuZp6ymD5NWim4379k9vKWLTlJp2d/Kuufu536eNasq9AHn9LxyWNkSzlTgnuBS6G6aeG5/FfKccH/9tatW5WQkKDu3bsXS1DXsqkLfpPd4dCi0Q8pIytbj7z/P32zZosGdmjq1C8lPVMznrpPkRXyjrgeOXVGE+b+osMJSfrrdHJJhY6rZLfbNOfdx9SqxxA1attPp44d0BeTB6hixA0Kr1rPqe9fB7bo1/lv6V8jv1JghSpau+RDzf1guIaOmefUL/l0vHZuWKCA4PCS3BVcwdRlm+RwOLRw2D+VkZWjR778Sd9u3K0Breo79UvJyNKMIb0UEeyfZx2fr9mhgwln9P0Td8rdzaJXF67Tm0s36tU7bimp3YCLcs/n0qIXH8w9n38wV9+s2aqBHZo49UvJsGrGU/fmez7/aes+3dmqgTreVFNpmVkaMWOhPli2Xk/fyudd1lTscYtufONZWby95cjOybePxc9Xzed/oG1DX9DpFesV0r65ms9/X7816CXriVOqfFcvRQ66XWvb3q3s5LNqMP1lNXx/vP6456kS3htcSci9D8pkMunIC/+WydNLlUe+KlvXPkr5eZHRxy20kioOfVrHJo9W1uGD8qrfWJWeGqMjzz8sR0a63CqGq8KgR+VeqbLcwyqX4t4ARc/lJHHs2LHGv2fOnKmYmBintujoaDVv3rxoo7vGpFuztGBTjH56+d9ys5jl7+2pod1a6cNl6/MkicnpmQrwzn/kIDXTqi4311bf5vXV6vnpJRE6CiF293qZLRY1attPkhRauZYatOqrHevmK/xe5yQx+tev1LLbAwqsUEWS1KbHUP2+7DOdOLJHlareaPRbPmeiGrbtp9jd60puR3BZ6VnZWrjtgJY+fZfczGb5e3noofYN9eGqbXmSxOQMq/y9PPJdz57jp9X5xmry9nCXJPW6uabeXLqx2ONHwaRbs7Qgepd+eumhv8/nXVvqw+Ub8iSJlzufD+3a0vi3r5eH+rdvrI+W/16ssePqWPx8tHfM28o5m6ab/++VfPtUua+PkqN36PSK9ZKkxDXROr1qkyrf01ux73yhGsPu15+v/p+yk3Iv8O4dO03dDq+Se3Cg0YbSZ/L0kl+7Ljoycqhkt8uRka4zi/+noL73OSWJHpHVlX0yXlmHD0qSMndtlSPLKvdKVZQVu19mbx+lb16v1HW/KurD70prd4BicVWPwKhYsaKqVasmSbLZbBo/frz69++vlJSUIg3uWrPryAlFhAQqyNfbaGtQLVwHjp1Wju3vMkvZNpsys7Pld4npZfUiK+nuto3kde5LJMq2vw5uVWQt54sAVWo01Ikju/P2PbDFqa/Z4qbwavWd+v65/Vdlpp1RvWb/KL6gUWC74k8rIshPQT5eRttNEaE6cDJJOfYLj2+7MrNz5HeJJPEfN9XQjzsOKjEtQxlZ2fpf9F71vrlmscePgtl15GSRnM8vlpiaIf9LJJQoXcfn/aSTi3+9bJ/g1o2VtG6zU1vypu0KaHSjTBaLAps1UOIF72efTlJGXLz8G9xQLDHj6nhWr6WchBOyp5012qwH98kjoppk/vurcea+GJl9/ORVv7EkybdVB9nTUpV1JFaSlHX4oM7+9pMc2VklGT5cYHeUzde15Kpuiujdu7fS0tL0xRdfaPLkybrpppu0YcMGBQQEFHV815SElFRV8He+dzDE30c5drvSMq0KPPdlIyU9UyaZ1Of1T+RmsahZzQg92bs99x1eo1LPnJR/cCWnNh//CspIO5O3b/JJ+QWEXtQ3xOh79swJLZ01XgOe/lSpyQnFFTKuQsLZdFXw83ZqC/H1Vo7doTRrtgLPffFPybDKZDLp1ulz5WY2q1n1SnqiSxOF+vlIkrrfFKWfd8ep+9Q5sphNuiE8RBP6MfWwrMk9n/s4tYX4e587n2cp0Df3YoFxPp/wmdwsZjWrGakne7XN93x+Ji1Dn6/YpMd7tS2RfUDR86ocptO/Oo8EWxNOK6hlI3lUDJHJYslz/6E1IVEeFYJKMEpciSW4Qp57B21nk2Vyc5PZ20f2tFRJkj09TYnffqrwEePkyLLK5OamY5NGSbb8pyMD5YnLSWLnzp1lMpnkcDh0/PhxxcbGqkuXLpoxY0aBpplarVZZrVanNkd2tjzdr/1RM5vd4XTvpiTZz102uPARIhX8fbV56jMymUw6k5ah6YvXaNgn8/X1MwNdftQIyg67wybJ+XN32G1SPp+l3W7P8zvisNslmeSw2/X9JyPVusdQVQivSZJYxtgd+RzfjtwRpQs/6Qp+3vrjpftzj+/0TL3zy2YN++YXff3QrTKZTJr60yaZTdLK5/rL3WLWtJ//0AtzVxmFbVA25J7Pndv+Pp//3VbB31ebpwy/4Hy+VsM+/UFfP93f6Xy+Lz5BI2cu1j+a1FWvJnVLYhdQDEwWi/MBf67N4XDIZMl/cpbJYs5z7kApM5nz/I02mc59fhd8Vh416ijkvqGKHz/i3D2JjRT2+PM6NnGUck6fLMmIgRLn8nTTcePGaezYsXr55Zc1ZswYDR8+XLt379aECRO0b98+lzc4ceJEBQYGOr3enFM+qjcG+njpTFqGU1tSarq83N3yTEU6/+UhyNdbo+/qqoMnEnWUIjVl3rujuhivOe8+Kkny9glUeuoZp37pZxPlF1Axz/LevoFKT3W+ypyemii/wFCtXvR/8vDyVfPOA4stfly9AG9PnUl3vsCVlGaVl5slz9RS4/j28dKLfVrrUEKyjp5JVUZ2jmZv2qMX+7SRv5eHvNzdNPIfLRQde1xxp6/v6fplTf7n8wwXzuddcs/niX+fz7/fGKPHPpynYb3b6UlGEa9pWYnJ8ggNdmrzCA2R9USCspNSJJNJ7sGB+bx/qiTDxBXY087K4uc8+83sHyi71Sp7RrrRFtitr1J+WXzBPYnblLZ5g/w79ijReFFwDkfZfF1LXB5J7NixY562iRMnavbs2erZs6f+85//6IknnrjiekaNGqURI0Y4tTl+/dLVMMq0epGVFHsySSnpmQo4d9/SlkPxalAtPE/J9Avl/uI45O5mKalQcZWenLgiT1vl6g20ftknTm1HDmxWRM3GefqGV7tJfx3YosrVb5Ik2XKydCx2p/rc/5qWz5mk7Kx0TX26haTcqqk5WZmaMry5HnzxO4VUiiry/YHr6lUOUezpZKVkWI0iJVuPnNBNEaF5HoFxIYfOHd/nRhPsDocsF5wPzCaTTMq9tw1lR73IsLzn89gCnM/PPQ5j+bZ9+nDZBn3+5L2qVjGoJEJHMUreHKPg1k10SDOMtuC2TXVszmLZ0jOUtveQgts00ckfV0qSPMMryrNSBaVs21M6ASNfWXEH5B4eIbOPr+zpaZIkrzr1ZD20z+mbvMnNXbJfdG52OCQLj7BB+XdVhWvOM5lMuu+++xQdHa3PPvtMmzZtuuIynp6eCggIcHqVh6mmkhQa4Kt29aI0ffEa5djsSkpN16c//66BHZ2Lmhw5dUaxJxMlSVk5OZo8f4UaVK+sSkF5y+Wj7KvTsLNSz5zUjg0/SJLiY3foz20r1PiWu/P0bdLhXv2+/DOlJB2X3W7T6sXvqfqNrRUUWlVPT1mjZ6dv1shp0Ro5LVr3PvmBQsKqa+S0aBLEMiDUz0ftakfonV82K8duV1J6pj5dvUMDWztXNj2SmKK4c7MCsnJsmrxkoxpEVlSlAF/5eLir7QXrsDsc+uC3raoU4KsaoXkfn4DSExrgq3Y3Vtf0H9eeO59n6NOfN+apbJp7Ps+dHZCVk6PJ369Ug2rhxvn8y982a3if9iSI5UT8NwsU2qWNKnRqLUmq2LOD/OrW0LHvcmdEHf50tuq89KTcAv1lcndX3ddH6PCn/5M9I7M0w8ZFbClnlL5zs4L/eb9kNsvs56+gPncrZfkCp36pm9YooOutsoTk1hLwqFZTfq07Kf2P9aURNlCiiuRSSEhIiNatWydPTyq2jbu3h8bNXqZuYz+Qt4e77u/cXF1urqNF0bsUc/i4nu/XRcnpmXrhy8XKzM6Rp5tFrW6orqmD+5Z26LhK7p7euufJD7T4i5f08/8myS8gVHc8NNV4xuFP376miBoN1aDVbbqxSXclnYzT5xPuksPhUPUbWurWByaU8h7AVWNva6dXFqxV96mz5eXupgfaNlCXG6tr8fYD2nn0lJ7v1UrJGVkaNfc3ZebYco/vGpU15e5Oxjpev/MWvb0sWre9M08Oh0P1q4Rq+oCuspgLdc0OxcA4n4/7KPd83qmZutxcW4uidyvmyHE9f2fnc+fzH3PP5+5ualWnmqYOvtVYx+FTZzTlh980bdEap3V//Ux/hfj5XLxJlEERA25TYPObtWvE68o8ekKbB45Qg3fGyj0kUOkH4hR952OypedOTT40/Qt5VamkTrt+kiPHphMLf9HeF6eU8h4gP6c+n67QIcNU7e2Zslszlbz0e6Vv+V2+rTvJs0ZtJX7zidKj18ri46vwEeNk9vCSLT1Vpz5/R9aDe0s7fFyBo8yWEr12ao+YHGXgburMHz8q7RBQgub4/ru0Q0AJuvvoxNIOASXIFBh85U4oN3654+3SDgElqP6/KLp0Panx2YIrdyqjpsyzX7lTKRjZ79q5IOzSSOKQIUMKXHXz3XfflY8PV0kBAAAA4FriUpLYvn37Aq/YvZzcZwgAAADg2lFmZ5teQ1xKEocOHVrccQAAAAAAyoBrZ2IsAAAAAKDYuZwkms1mWSyWPK/z7bt27SrOOAEAAADgioriwffF8bqWuJwkVq9eXVlZWfm+unfvXpwxAgAAAABKiMvPSTSZTLJYLJd8DwAAAABw7XM5SQQAAACAss5OedNCK5LCNYwkAgAAAED54PJI4rFjx9ShQ4c87Q6Hg6I1AAAAAFBOuJwkLl269LLv16hRo9DBAAAAAEBhXGuVRMsil5PEjh07FmccAAAAAIAyoEjuSQQAAAAAlA9UNwUAAABQbjDdtPAYSQQAAAAAGEgSAQAAAAAGppsCAAAAKDfszDctNEYSAQAAAAAGkkQAAAAAgIHppgAAAADKDYe9tCO49jGSCAAAAAAwkCQCAAAAAAxMNwUAAABQbjioblpojCQCAAAAAAwkiQAAAAAAA9NNAQAAAJQbdqqbFhojiQAAAABwDYiNjVX37t1VvXp11a5dW1999VW+/U6ePKnBgwerfv36ioyMVP/+/XXq1CmXt0OSCAAAAABlnM1mU9++fTVw4EDFxcVp4cKFGj58uLZu3Zqn7+LFi9WxY0ft3LlTBw8elIeHh5588kmXt8V0UwAAAADlRnmtbvrLL7/Izc1NgwcPliTVq1dPgwYN0syZM9W4cWOnvkOGDDH+7eHhof/85z/q1q2by9tiJBEAAAAAyrj169erXbt2Tm0tW7bMdyTxYgkJCQoMDHR5W4wkAgAAAEAxs1qtslqtTm2enp7y9PR0afn4+HhFRkY6tYWFhen06dOXXS4zM1MvvfSShg4d6nKsjCQCAAAAKDfsjrL5mjhxogIDA51eEydOdHm/bDZbnqm0NptNJpPpksvExcWpY8eOuuGGG/Tcc8+5vC2SRAAAAAAoZqNGjVJycrLTa9SoUfn2jYqKMl633XabJCkkJCRPhdKEhASFh4fnu44lS5aodevWuv/++zVjxgyZza6nfkw3BQAAAIBiVpCppbGxsXnamjVrpjfffNOpbe3atWrTpk2evuvXr9eQIUO0YMECtWzZssCxMpIIAAAAoNxw2B1l8lVYffv2VXx8vPFsxOjoaC1YsEAPPfRQnr7vvPOOnnnmmatKECWSRAAAAAAo83x8fLRw4UK99dZbCgsL04MPPqhZs2YZxWyGDRumr7/+WpK0f/9+TZ061WnaalRUlLZs2eLStphuCgAAAADXgGbNmmnz5s35vjd9+nTj3xs3bizUdkgSAQAAAJQbjsLP7LzuMd0UAAAAAGAgSQQAAAAAGJhuCgAAAKDcsBdBJdHrHSOJAAAAAAADSSIAAAAAwMB0UwAAAADlhoPypoXGSCIAAAAAwECSCAAAAAAwkCQCAAAAAAzckwgAAACg3HDYSzuCax8jiQAAAAAAA0kiAAAAAMDAdFMAAAAA5YadR2AUGiOJAAAAAAADSSIAAAAAwMB0UwAAAADlhoPppoXGSCIAAAAAwECSCAAAAAAwMN0UAAAAQLlhtzPdtLAYSQQAAAAAGEgSAQAAAAAGppsCAAAAKDcoblp4ZSJJzDl8qLRDQAk6W720I0BJOvPHjtIOASUouHWz0g4BJaj+v+qWdggoQbu+3FvaIaAE1fistCNAaWK6KQAAAADAUCZGEgEAAACgKDioblpojCQCAAAAAAwkiQAAAAAAA9NNAQAAAJQbdsqbFhojiQAAAAAAA0kiAAAAAMDAdFMAAAAA5QbVTQuPkUQAAAAAgIEkEQAAAABgYLopAAAAgHKD6aaFx0giAAAAAMBAkggAAAAAMDDdFAAAAEC5wWzTwmMkEQAAAABgIEkEAAAAABiYbgoAAACg3KC6aeExkggAAAAAMJAkAgAAAAAMTDcFAAAAUG44HEw3LSxGEgEAAAAABpJEAAAAAICB6aYAAAAAyg071U0LjZFEAAAAAICBJBEAAAAAYGC6KQAAAIByg+qmhcdIIgAAAADAQJIIAAAAADAw3RQAAABAueGgummhMZIIAAAAADCQJAIAAAAADEw3BQAAAFBuMN208BhJBAAAAAAYSBIBAAAAAAammwIAAAAoN+wOppsWFiOJAAAAAAADSSIAAAAAwMB0UwAAAADlBtVNC4+RRAAAAACAgSQRAAAAAGBguikAAACAcsNBddNCYyQRAAAAAGAgSQQAAAAAGJhuCgAAAKDcsFPdtNAYSQQAAAAAGEgSAQAAAACGK0437dy5s0wmU4FW+sMPP8jf3/+qgwIAAACAq+FgummhXTFJHDNmTIFX6uPjc1XBAAAAAABK1xWTxK5du+qLL74o0EotFstVBwQAAAAAKD0uVTf99ddfjX/v379fycnJatasWb59TSaT7r///qKJDgAAAAAKwOFgumlhuZQkfv7558a/Z86cqZiYGE2ePNloO3r0qCIiIoo+OgAAAABAiSpwdVNvb2+nojRffPGFWrVqpZSUlCINDAAAAABQ8lwaSbzQPffcI0lavXq1XnvtNaWkpGjlypUKCAgo8uAAAAAAoCAcdntph3DNcylJHDJkiEwmkxwOh44fP66YmBhFRUVp2LBhuuuuu4o7RgAAAABACXEpSezUqZMkyW63Kz4+XoGBgVq9erXWrVunLl26KCQkpDhjBAAAAACUEJeSxAceeCBP29mzZ/Xee++pWbNmmj59uvr27VvkwQEAAABAQdjtVDctrALfk3iev7+/nn/+ed11113q0aOHKleurObNmxdlbAAAAACAEnbVSeJ5tWrV0oYNG1SxYsWiiOeal5lj05Rft2l93AnZHQ79o25VDbulgcwmk1M/h8Ohrzfv17wdh5SZY5O72azvHugud4tZaw8d17trY5RqzZYk3XlzlB5seWNp7A5clHL6L/0y+yWdSYiV2eKmVj2f1I3Nb79k/8TjB/TL7NFqf/sLqhzV2GjPycrUb/Nf1+E9a2S321S3aR+16/usTOYCFyJGcXBzV+AdD8ij7s0ymc3K2LJeZxd/I13wPKbA+x6VR616TouZff2Vsek3pcyfKbeI6godNl62lDPG+2eXzFHm5rUltRdwUWZ2jiYvXqd1f/4lm8OhXg1r6ekerWQ2O5/P7373OyWlZcrdknuc1q0cqv8O7GG8f+psut78cb22Hj4um92hPo1q65merUt0X3BlJncPhQx4WD43NZHMZqX+vkpJ3810Or4lyadJKwX3+5fMXt6yJSfp9OxPZf1zt1Mfz5p1FfrgUzo+eYzTsY6yJ2LQ7ar+6ACta39vvu8HNK6nBu+Ok2d4RdnSMrTrPxN06ue/z9dRwx5Q1GMDZfH20pnoHdr+yBhln04qqfCBYlPoJFESCeIF3v5tu+xy6IcH/6GMbJsen7tas7ceUP8mtZ36fbpxrzYePqlP7umgEB8vJaRmyHLui0eIj6c+vOsWBXh5KCE1Qw98u1K1KwSqQ63KpbFLuAK73aaFnzymJp2GqH6rfko8fkDfTR+gCuE3qGKkc7KQkZakX+eMVfyhzcq2puVZ1+ofJsnhsOuBMcuVnZWh+e8N1rbVX6lxx/tLandwGQG3DZLMJiVMfEYmD0+FPPKifNr1UPqan4w+yd9+4LSMycNTFUe9pbQ1yyRJZm9fZcXtV+J7r5Zo7Ci4qUs2yO5waNGI+5SRnaNHPl+sb36P0cA2DZz6pWRYNePh2xQZkrfKtzU7R//+fLFub3qDJtzdWRazWSeSU0tqF1AAIfc+KJPJpCMv/FsmTy9VHvmqbF37KOXnRUYft9BKqjj0aR2bPFpZhw/Kq35jVXpqjI48/7AcGelyqxiuCoMelXulynIP4292WVaxxy268Y1nZfH2liM7J98+Fj9fNZ//gbYNfUGnV6xXSPvmaj7/ff3WoJesJ06p8l29FDnodq1te7eyk8+qwfSX1fD98frjnqdKeG9wMYeD6aaFxfBEEUrPytGiXYc1rH0DuZnN8vd015CWdbUwJs6pX1K6VTM27dX4ns0V4uMlSaro522MNtarFKwALw+j/aZKwTqZmlGyOwOXHdm3XiazRfVb9ZMkhYTXUt3mfbV70/w8fXOyMhUe1ViDXlgsL59gp/eyrGnavel7tes7UmaLmzy9/dWi+6PatXFeiewHLs/k4Snv5rcoZdE3kt0uR2aGUn/5QT4tO152Od8OvWXds022hGOSJLOPnxwZeS8QoGxJt2ZrwZZ9evofreRmMcvfy0NDOzbWD5v35umbnGFVgLdnvuuZG71HYQG+eqB9I1nOzQioFOhXrLGj4EyeXvJr10WJ/5uZe3xnpOvM4v/Jr103p34ekdWVfTJeWYcPSpIyd22VI8sq90pVJElmbx+lb16voy+RJJR1Fj8f7R3ztrb/e/Ql+1S5r4+So3fo9Ir1kqTENdE6vWqTKt/TW5JUY9j9+vPV/1N2UrJkt2vv2GkK69NJ7sGBJbIPQHG64kji+PHjC7zS5557Tl5eXlcV0LVs98kkRQT6KuiCLwsNwkO0/3SKcux2uZ37grD60DE1iQhVuL/PZddndzi08fBJxSWl6sWuTYo1dly947FbVaVGU6e2StUaKmbD//L09Q+urKadH8x3PSePxCggJFLevn8nj5WqNVTisT9lt+XIbCmSgX9cJffIGrIlJsiR/vcoUPbhA3ILj5TMZimfZzKZPDzl076HTk9/+e82b1/ZM9JLJGZcvV3xCYoI9leQz99/yxpEhunAiUTl2OxyOze1NNtmV2Z2jvw8PfJdz88xh3RPq/olEjOunmf1WspJOCF72lmjzXpwnzwiqjkd35n7YmT28ZNX/cbK3LVVvq06yJ6WqqwjsZKkrMMHjQQSZdvxebkzQEI6tLxkn+DWjZW0brNTW/Km7QpodKNMFosCmzVQ4gXvZ59OUkZcvPwb3KDE1ZuKJ3CghFzxW2d2dnZJxFEuJKRmKsTH+WpysLenbHaH0rJyFHhudHD/qRSF+3vr9Z83a33cSfl7umtg09q6tX51Y7l/zVqh/adSFODlobE9minYJ/+r1Ch9ackn5RdUyanNx7+CMtPOFHg9Pv4VnNq8/UNkt+coKzNVXr5BhYwUhWEODJY9NdmpzZ6aIpPFTSZP73xHB71bdlT2ob2yJSb8vR4fP3nd1EyeL70j29lkZWz6Telrlxd7/CiYhJR0VfDzdmoL8fVWjt2hNGuWAs8ljykZmTLJpD5vfSs3i1nNosL1ZLcWCj13EfDPE4myZufogY9+0MmUNNUKC9bI3m0UFRpU0ruEy7AEV8hz76DtbLJMbm4ye/vInpZ7ccienqbEbz9V+IhxcmRZZXJz07FJoyRb/tMVcW3zqhym07/+7tRmTTitoJaN5FExRCaLJc/9h9aERHlUCCrBKJEfB9VNC+2KSeKrrxbtfTNWq1VWq9WpLTs7R57u1/4oid3h0MW/kvZzc6IvLHOQlpWj1QeP6ZWezfVi1ybal5CsJ+atVbi/j5pXzb2/88sBXWSzO7TjWKLGLYvWY23r6x91q5bMjqBA7A5bnrnvdrtNpouKFV2Jw2GTLvoNcpwfnSrgulD0TCaznI9k5Y4wXIZPq85K+f4Lp7a0lYuU9utCSZJbRJSCBz0pyaT0tcuKMFoUls3huLheieznjscLj+0Kfj7aPP4hmUwmnUnP1PRlGzXsq5/09aN3yGQyKd2apeUxhzSlf3cF+3jpi7Xb9dSXP2nesLuNQjcoA0zmPOfZ3GNeToVrPGrUUch9QxU/fsS5exIbKezx53Vs4ijlnD5ZkhGjBJgsljynfZPFIofDIdMljl+Txcz9cCgXSvwv1MSJExUYGOj0mvrT+pIOo1gEeHnoTIZzApyUYZWnm0V+nu5GW5C3h1pXr6Q21SvJZDKpbliQeterqlUHjzktazGb1Diigh5uVU+ztzJ9pSz4/JUuxmvhx49Kkrx8AvOMGmakJsrHv2AFnbx8gpSR6nxFMiM1UW7uXvL08i9U3Cg8e3qazL7On4PZz1+OLKscmXmnj7pH1pDZx09ZB5yrHl74hTPnaKzO/jRXXo1aFUvMuHqB3p46k57p1JaUlikvd0ueqaXnk8YgHy+Nvq29DiYk6WjSWaPtX21vVkV/H7lZzBpySyOlZGQqNuFMiewHXGNPOyuLn3PhIbN/oOxWq9P08MBufZXyy+IL7kncprTNG+TfsYdQ/mQlJssj1Ll+gEdoiKwnEpSdlCKZTHnuP8x9/1RJhgkUC5eG72rWrJlvu8PhkMlk0rJly1S7du18+1xs1KhRGjFihFNb9szyUeXvxrAgxSWlKiUzyyg8sy3+tBqEBzs9AqNWhQDFJp51WtZkMsnjElel3C1meblZii9wuGzI2BV52sIiG2jzr584tR07tFnhFzzawhUVI+sr6eQhZaYny8sn0FhPpWoNeQRGGZB99JDcwirL5O1rTC31iKqrrMMH8pTIlyTvZu2VucOFe1LMZslmK+pwUUj1qoQq9tQZpVxQlGbL4eNqEBGW5xEYF3I4cv82nh8lrBUWovSsv2/bMJlMMskkD87pZUpW3AG5h0fI7OMre3ru8e1Vp56sh/Y5Hd8mN3fJftHx6nBI3DNeLiVvjlFw6yY6pBlGW3Dbpjo2Z7Fs6RlK23tIwW2a6OSPKyVJnuEV5VmpglK27SmdgGFgumnhufTNMzs7W8uXL8/3VbVqVWVlZbm8QU9PTwUEBDi9ysNUU0kK9fVS2+qV9O7aGOXY7UrKsOqzjXvzPP6iS50IxRxP0u9xuVNTDp1O0dI9R9TjhkhJ0uytB5R27ktFfHKaPtu4V3c0iCrRfYHrajTorLTkk9oT/YMk6cThHTq0c4VuanN3gdbjG1BR1evdovWL3pLdlqOM1ERtWv6BGnd8oDjCRgHZzybLumeb/HvfK5nNMvn6y6/r7UpbvTTf/p43NpL1z5g87R41b5TJIzfpsFSoJP/udyrjj9XFGjsKLtTfR+3qVNX05RuVY7MrKS1Tn/62VQPb3uzU78jpFMWeOiNJysqxafKP69QgMsyoYHpPq3r6eOUWY1Ry5pptqlohQNUq5H1cBkqPLeWM0nduVvA/75fMZpn9/BXU526lLF/g1C910xoFdL1VlpBQSZJHtZrya91J6X+UjxlRcBb/zQKFdmmjCp1yn2tasWcH+dWtoWPf5Z73D386W3VeelJugf4yubur7usjdPjT/8mekXm51QLXBJeyM3d3d9WqVSvf93x8Ll+h83rzUo+menXZZv3jox/l7e6mfzWro861q+jH3YcVczxJz3ZuJC83i97s21oTV2xR0jKrgr099XL3pqpTMXf0aP+pZN35+TJ5uFkU6OWhB1vWVY+6kaW8Z7gUdw9v9X34A/0y+yWt/n6SfPxD9Y9/TZV/ULgk6be5r6lS9Ya6sfltV1xXt/te18/fjtYnL7eXu4ePmnZ5ULUadrvicigZZ+Z8rKB7HlbY2PfkyLIqbeViWXdGy7tpO7lXraWUH3LvPzR5+cgtrIqyjx7Ksw6P2jcp6P7hcmRnyWHNUOqvi5QRTZJYFo27s6PGzf9N3d74St4ebrq/fUN1qR+lRVv/VMzRBD3fp62SMzL1wpwVyszOkaebRa1qRWhq/+7GOrrdVFNxp5J197tz5WY2q35EqN4a0KPA9yyj+J36fLpChwxTtbdnym7NVPLS75W+5Xf5tu4kzxq1lfjNJ0qPXiuLj6/CR4yT2cNLtvRUnfr8HVkP5n00Cq5NEQNuU2Dzm7VrxOvKPHpCmweOUIN3xso9JFDpB+IUfedjsqXnPpbs0PQv5FWlkjrt+kmOHJtOLPxFe1+cUsp7ABQNk8OFu2tr1qypgwfzvyeuV69emjp1qurXv/oS36kfjLrqZXHtmVl9YmmHgBLU7+cBpR0CSlBw62alHQJK0LElv5V2CChBu74kGb6e9Mm+dj/vfsP2l3YI+Zo33bXb8y4nNjZWDz/8sPbt2yd3d3eNGzdOgwYNuuwyv//+u1q3bq3169erdevWLm2n0Dc6cTUUAAAAAIqXzWZT3759NXDgQMXFxWnhwoUaPny4tm7detnlxo0bJ4ulYPfCuzTdNCEhQffff3++723fvr1AGwQAAAAAFMwvv/wiNzc3DR48WJJUr149DRo0SDNnzlTjxo3zXWbRokWyWCyKjCzYrWsuJYnvvvvuJd/r2rVrgTcKAAAAAMWhvFY3Xb9+vdq1a+fU1rJlS33yySf59j979qxGjhyphQsXqnv37vn2uRSXksQHHrhydcXzj8MAAAAAADizWq2yWp2fqe7p6SlPT0+Xlo+Pj88zOBcWFqbTp0/n2//RRx/VgAEDVKdOnQLHetX3JO7f73xDaERExNWuCgAAAADKtYkTJyowMNDpNXGi6wUdbTabLq45arPZ8h2o+/TTT3XgwAGNHj36qmJ1OUl85JFHnH7u16+fjhw5YvzsQpFUAAAAAChWDrujTL5GjRql5ORkp9eoUfk/5SEqKsp43XZb7mPUQkJCdOrUKad+CQkJCg8Pd2rbtWuXxowZo6+//rrABWvOczlJXLhwofHv/fv3y2QyqWrVqkYbU00BAAAAIH+enp4KCAhwel1qqmlsbKzxWrBggSSpWbNmWrdunVO/tWvXqk2bNk5tM2bMUEpKipo1a6agoCAFBQXp8OHD6t69u1555RWXYnU5SbxwpPDll1/WCy+84OqiAAAAAIBC6Nu3r+Lj4/XVV19JkqKjo7VgwQI99NBDTv0mT56stLQ0nTlzxnhVq1ZNy5cv19ixY13alstJ4vmRwlmzZunkyZPq37+/q4sCAAAAQIlwOBxl8lVYPj4+Wrhwod566y2FhYXpwQcf1KxZs4xiNsOGDdPXX39d6O1ILlY3feONN5SWlqbBgwdrx44dWrJkiaTcR2NkZWXJ4XAoPT29SAICAAAAAOTVrFkzbd68Od/3pk+ffsnlYmNjC7Qdl5LE48ePKycnRwcOHFBoaKj8/PyMjZ0v42qz2Qq0YQAAAABA2eNSkvj2229r9uzZWr16tSZNmqQhQ4Zo9uzZmjJlitHnu+++K7YgAQAAAMAVdru9tEO45hX4OYkvvPCCMjIynKqdSlQ3BQAAAIDy4Kqqm06aNEmvvvpqsQQEAAAAACg9Lk03lXJvkjyvfv36slqtio2NVVRUVHHEBQAAAAAF5rAXvpLo9c7lkcRFixY5/fzpp586JYhFUdYVAAAAAFC6CnxP4nnNmzd3+nnTpk2FDgYAAAAAULpcnm56Jecf4ggAAAAApcXhoLppYV31SCIAAAAAoPwhSQQAAAAAGIpsuikAAAAAlDaqmxYeI4kAAAAAAANJIgAAAADAwHRTAAAAAOUG000Lj5FEAAAAAICBJBEAAAAAYGC6KQAAAIByw+6wl3YI1zxGEgEAAAAABpJEAAAAAICB6aYAAAAAyg2qmxYeI4kAAAAAAANJIgAAAADAwHRTAAAAAOWGw05108JiJBEAAAAAYCBJBAAAAAAYmG4KAAAAoNygumnhMZIIAAAAADCQJAIAAAAADEw3BQAAAFBuOBxUNy0sRhIBAAAAAAaSRAAAAACAgemmAAAAAMoNO9VNC42RRAAAAACAgSQRAAAAAGBguikAAACAcsNhp7ppYTGSCAAAAAAwkCQCAAAAAAxMNwUAAABQbjioblpojCQCAAAAAAwkiQAAAAAAA9NNAQAAAJQbDgfVTQuLkUQAAAAAgIEkEQAAAABgYLopAAAAgHKD6qaFx0giAAAAAMBAkggAAAAAMDDdFAAAAEC54bBT3bSwGEkEAAAAABhIEgEAAAAABpPD4aD8TymwWq2aOHGiRo0aJU9Pz9IOB8WMz/v6wud9feHzvr7weV9f+LxxvSJJLCUpKSkKDAxUcnKyAgICSjscFDM+7+sLn/f1hc/7+sLnfX3h88b1iummAAAAAAADSSIAAAAAwECSCAAAAAAwkCSWEk9PT40dO5aboK8TfN7XFz7v6wuf9/WFz/v6wueN6xWFawAAAAAABkYSAQAAAAAGksTL+Pnnn9WpU6cCLWMymZSTk3PJ9wcPHqy5c+fmaY+MjFRsbGwBI5R++ukn7dq1q8DLAde7bdu2adiwYQVapiSP75UrV6p9+/YFWgYla+/evdq5c2ee9i1btshqtZZCRChOn3zyiQYPHlygZfbv36+oqKhiiQelY8yYMRo3blyBl7ua75RAabquk8TU1FQNGTJEoaGhqlSpkp599lnZbDaXlo2KitLx48ev2M9msyk6Otp4HTt2THv37jV+3rt37yWXnTJlisLDwxUeHi5fX18FBgYaP8+ePVuS9OWXX2rjxo2XjSEhIUG+vr4u7RcK7uzZs5o0aZIaNWqkqlWrqmrVqmrevLneeecdZWZm5unfsGFD43MMDw+Xl5eXgoKCnNrGjx9fCntSvqSnp+vZZ59VnTp1VKNGDbVo0UILFiww3k9KSrrksVMSx/eYMWPk5+fn9LmHh4dr+PDhBdpPju/idbkEf/78+frqq6/ytN955506duxYgbYTGxuryMjIqwkRRWDlypXy8vJSVFSU08tkMrm07MVf/seNG3dViQSK19NPP61JkyZd8v0ZM2bIz8/P6XcgMjLS5UR/xowZeS4kDB48WDNmzLj6oIFS4lbaAZSmp556SiaTSYcPH5bVatU999yjSZMmafTo0Vdc1mazyW63X7FfZmamxowZY/xsMpm0atUqrVq1SlJuwjB58uR8lx05cqRGjhwpSRowYIBuuOGGq/qjs23bNqWnp2v//v2qXbt2gZfHpWVkZKhdu3Zq1aqVFi1apKpVq0qS9uzZo+eee07ff/+9li9fLrP57+sx27dvN/598uRJNWjQQD179tQXX3xR4vGXZ0888YTc3d21fft2eXt7a8+ePerTp4+Cg4N1yy23XHbZkji+pdxjvLBfJDm+C+fYsWN67LHHtGrVKnl5eempp57SqFGjLtm/W7du2rNnj1Pb+USxatWqWr9+/RW36eXlle8FJJSu5s2ba82aNcbPOTk5cnd3L8WIUFh9+vTRH3/8YfyckpIii8Wi//73v0Zb37599fHHHxs/33HHHU4Xf/bv369u3bqVSLxAWXLdJonHjh3T4sWLFRsbKx8fH/n4+Ojjjz9WixYt9Nxzz132D0NaWpri4+O1b98+ValS5bLb8fX11dKlS5Wamqovv/xSu3btkpeXlzp06KBbb73VpauU8fHx+u2337RhwwYNHz5cwcHBLu9nRkaGnnvuOfXp00fDhg3TokWLnBIWFM68efPk5+fn9AdGkm688UbNnTtXNWvW1IYNG9S2bVun9x0Oh5YsWaLnn39e06dP15IlSzRo0CBNmjSJ0YQiMnfuXMXFxcnb21tS7mfy6KOPav78+ZdNEkvy+I6NjdXKlSuNn93c3Ao0xZTju/Duu+8+dejQQXPmzFFCQoL69OmjKlWq6IEHHsi3/88//1yo7bl6AQLXDrvdLmoAlk2LFy92+rl9+/aqWbNmsV2U5XcB5cl1+20iJiZGLVq0kI+Pj9EWFRWl4OBgHTly5LLLfvvttwoKCtKHH36Y7/sTJkzQhAkTjJ+TkpLUrFkz7d69W926dVPTpk01ZcoUDR069IpxHj16VHfccYfefPNNPfnkk+rSpYtiYmJc2sf4+Hj16tVLbdu21YIFC+Tv76+77rpLSUlJLi2PKzt16pSqV6+e73vu7u6KiIhQQkKC0bZx40Y9/vjjatSokebMmaMFCxaoe/fu+uCDD9SvXz/ddddd6t27t1566SWdPXu2pHajXKpYsaKOHj3q1Hb06FFVqlTpssuV5PG9efNmffLJJ8bryy+/dHp/165duvXWW51GK8/j+C68jRs36vjx4xo/frw8PDwUERGhd955R2+++eZll/vuu+/Upk0bNW7cWI0bN1abNm00Z84cl7a5b98+ZWdnX9U96Cib4uPjjenpixcv1owZM7R169bSDQp5TJo0Sd7e3tqxY4e+/vrrYtnGhb8Ls2fP1owZM7R///5i2RZQ3K7bJPHUqVOqUKFCnvYKFSo4fam/WHx8vF577TUtX75chw4dyvdqVGhoqEJDQ42fFy9erJtuuknTp0/X7bffrv79++unn37SnDlzlJKSYvRLT09XamqqcRVq+vTp6tq1q8aOHasBAwZoxIgRmjZtmgYNGqR33333kjEeOXJEb7zxhlq1aqXevXvr3Xffldls1rfffqtGjRqpRYsWmj59uk6ePOnS/xUurUuXLpcsHrRy5Urt2bNHbdq0Mdrq1Kmjvn37as2aNZoxY4Zq1KihoUOHavHixerXr582bNigt99+W82aNZO/v39J7kq58+abb2rAgAH6+uuv9euvv+qVV17RqlWr9Nhjj11ymZI8viWpX79++uqrr4zXxYlp1apVNWbMGA0cONBo4/guOtu3b1enTp2cRnzbt2+vgwcPKjs7O99ljh49qmHDhmnevHnaunWrtm7dqoULF+r55593+jL422+/aenSpcrKynJaftasWQoJCcn3IsTZs2f12muv6b333iuiPURJ2Llzp2JjY3X27FkdPHhQO3fu5PgrQ3bt2qW+ffvqjz/+0Pz587VkyRJ99tlnuu+++/Tnn38W6bZ27typmJgYORwOo7DVmTNninQbQEm5bqebVqlSJd/CAvHx8YqIiMh3mYMHD+r222/XK6+8oqZNm2rBggXq2bOnDhw4oBdeeMGY1vbvf/9bbm5//9eGhYUpLi5O2dnZxjTWuLg4eXl5ORWc6N27t9zc3LRixQpVq1ZN3bt31+DBgxUQEGD06dChg6Kjo40CO3fffbdq1KhhvG+32zVs2DBFRkZq5cqVqlWrlhwOhxISEhQWFqaxY8eqf//+evvttzVu3Di+jBTSzTffrLfeekvdunVT586d1aBBA9lsNm3evFmbN2/WrFmzFBYWZvQPDg5Wr169LrvOunXrqm7dusUdernXr18/3XzzzZo/f762b9+u+vXra8OGDfLw8Mi3f0kf35IUHR2tDz74QHa7XTk5OcrKylJaWppxT5y/v79at25trIPju2idPn1aISEhTm0mk0mBgYFKTEw0Rp1feOEF+fn56ZFHHlH16tVls9m0Z88eBQcHy2Qyae/evbJarU6/W99//718fX3Vpk0boz0mJkYzZszQunXrdMcdd6hr165O9zqZzWaFhoYqMDCwBPYeRcFut2v27Nnq0qWL5s2bp6eeekqSKFpTBmzatElDhw6Vh4eHxowZozvuuEOS5Ofnp+XLl+ubb77RP//5T9ntds2bN0833HBDobaXkpKiVatWqWbNmlq1apVefvllSbmDEsC16LpNEhs1aqRt27bp1KlTxqjApk2bZLFY8r0PKSMjQ3feeadefPFF9e/fX1Lul8OVK1fqtddeU1pamvEl8mI9evTQL7/8onr16qlly5ZKT09XTEyMZs2aJYvFYvRbuXKlUwWtevXqScotWrNixYpL7su0adPUsGFDSblfMubPn+/0fnJysmrWrKnU1FRJ0g033KD333//Sv9FcNHgwYPVr18/rVmzRm+++aaCg4P1+OOPq127dk6/E2vXrtXtt9+e7zrWrFmjRx991KmtSpUqTkVuUHB16tTRc889l+97nTp10oYNGySVzvF9fgQrPj5eZrNZ7u7u8vT0VHh4+CXvaeH4LlpVqlTR7t27ndqys7OVnJysihUrGm09evRQWFiYIiIiFBYWprlz52ratGkaOHCg7Ha72rVrp1mzZhnJvyS9/fbbTp/3li1b9M9//lMzZsxQ3bp19cMPP+i2227TE088occff1xS7j2uF58HULbNmTNHjRo10osvvqghQ4ZowIABFLspI1q0aKHvv/9eNWvWNNr+85//qHr16ho2bJgGDhyogQMHKi4u7pK3jRTEe++9p3vuuUdt27bV66+/ro4dOxZ6nUBpum6TxMDAQD3xxBO666679N///lepqal68MEHNW7cuHwLP3h7e2vr1q0ymUxKTExUUFCQzGazAgICLlu98Lw33nhDL730ku6++2716tVL8+bNc7nAxKxZsy753uDBg5WRkeHSelB8AgIC1Lt3by1btkyRkZH5VkJr164dVxRL2Lp169SvX79838vOzladOnW0YcOGUjm+u3XrpsaNG2v37t1XrLaK4tGmTRs999xzslqt8vT0lJRbjKpFixZOn1+XLl0UFRWllJQULVmyRHa7XYMGDZK7u7syMjLUt29f7d69Wxs3btSAAQPybOf48eO677779PHHH6tr166ScpP5lStX6q233sozJRWlIyYmRj179jR+vlIBksTERI0aNUo//vij6tWrp/r162vChAkaO3ZscYcKF12YIEqS1WrNc7xdnCCuWLHC6fcgPT39its5cOCA3n//fUVHRys0NFRTp07VzJkzL1kAC7gWXLdJoiS9/PLLCgkJ0bBhw+Tu7q6xY8c63ftzsfP3rZyftpbfc3NGjx59yS+Hfn5+CgwMNKYfZmRkKDU1VX5+foXfGVwzVq9erVdffVXLli0r7VDKvbZt217yeYcbNmzQ008/bfxcGsf3zp07NWbMGKey++fVqVNHI0aMuOSyKLzatWurZ8+euvfeezV+/HgdPnxYw4cP1zfffJNv/6ysLG3cuFFubm5yc3NT8+bN5e7uruzsbPn7+6ty5cry9fVVQECA0+9JeHi49uzZI5PJ5DR7JTw83KWLECh+LVq00OrVq13un5mZqW7duumZZ54xZv28//77atWq1RVvKUDZdccdd6h58+Z52i91m4KU+yir7t27a9q0acYMhK+++kodO3ZUly5dii1WoLhd10miyWTSU089ZdxDUBRee+01p58nTJigjz76yCiLnJOTo7Vr12rMmDHy8vKSn59fnmUu1rNnT23ZsuWS091uvfVW49/Dhw/X7Nmznd53OBxKT09XeHh4nmWfeeYZPf/8867uHs7566+/nO4VOy85OTnPM5jOi4uLk8Vikc1mc+nKJApv5cqV6tmzZ76/+5LUpEmTAq2vOI7vS4mIiMgzCsrxXfQ+/PBDo3p0YGCgZs6cqc6dO+fbNzQ01BglWrp0qaZPn67du3fLZrPJZDLJbDarfv36mjJlitPUUyn3701mZqYqVqyY7whVUFCQhg8fXvQ7CJf4+vqqQYMGLvf38vIyksLzQkND9ccffygoKEg//vhjcYQJFx05ckQtWrTI03727FlZLBZNmTIlz3tHjx5VUFCQgoKCCrStsLAwffvtt2rZsqXRVqdOHe3atavA6wLKkus6SSwJL774ol588cVCr2fmzJlO0x8uZdq0aZo2bVqht4fLi4yM1F9//VXaYcAFrVu3dnoWYVEqquPbVRzfRc/Dw0OjR4/W6NGjXV4mJiZGgwYN0g8//KA2bdoYo4Y2m03r1q3T7bffrjVr1qh+/fourzMoKEjPPvtsgeNH6bkwQTyPpKBsqFq16iVnkRSHCxPE8/hdwLWOJPEqNW3a9JLTzl5//XU98sgjRbq9AQMGXHK6w/kHQePasXHjxkuObkm55fOpcFo01q1bd9n/6/ymlpbk8X2l34VNmzapatWqRbY9FJ7D4TBGji8cFXQ4HMrOzpbdbi/F6AAAKDyT40p3Zl/HsrOzlZ6eXiLlyJOSkhQYGOhyMRsA1w6O72tXZGSk1qxZk+dCwpIlS/TRRx9px44dRtJoMpnUsGFDPfLII/nO/MjMzJS3t3e+z+g978svv+SetjLKarUqOzu7QHUE7Ha7kpOTFRwcXIyRoSSdv13Ex8enQMuV5HdKoCiQJAIAcAkk+ACA6xFJIgAAAADAwKVRAAAAAICBJBEAAAAAYCBJBAAAAAAYSBIBAAAAAAaSRAAAAACAgSQRAAAAAGAgSQQAAAAAGEgSAQAAAAAGkkQAAAAAgOH/AdZuTHbgoK6HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 전체 상관관계 행렬 계산\n",
    "full_corr_matrix = df.corr()\n",
    "\n",
    "# 시각화용 상관관계 행렬 생성 (시간 및 도시 컬럼 제외)\n",
    "visualization_columns = [col for col in df.columns if 'Year' not in col and 'Month' not in col and not col.startswith('SIDO')]\n",
    "vis_corr_matrix = df[visualization_columns].corr()\n",
    "\n",
    "# 상관 계수 행렬 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(vis_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('선택된 변수 간 상관 관계')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소     오존  일산화탄소   아황산   초미세\n",
       "측정일시                                       \n",
       "2012-01-01  0.036  0.009    1.0  0.01  57.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['이산화질소', '오존', '일산화탄소', '아황산', '초미세', '미세'], dtype='object'),\n",
       " Index(['미세'], dtype='object'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.columns , df_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature.values, df_target.values, test_size=0.2, random_state=2023\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결정계수(R Squared)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288632169974571"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "y_hat_sv = svr.predict(X_test)\n",
    "r2_sv = r2_score(y_test, y_hat_sv)\n",
    "mse_sv = mean_squared_error(y_test, y_hat_sv)\n",
    "r2_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986545254204773"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=2023)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_hat_rf = rfr.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_hat_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_hat_rf)\n",
    "r2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986545254204773"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(random_state=2023)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_hat_rf = rfr.predict(X_test)\n",
    "r2_rf = r2_score(y_test, y_hat_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_hat_rf)\n",
    "r2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 2023,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       " 0.5782358691317517)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = { 'max_depth' : [1, 3, 5, 7], \n",
    "    'min_samples_leaf' : [1, 3, 5, 7],\n",
    "    'min_samples_split' : [2, 3, 5, 7] }\n",
    "grid_rfr = GridSearchCV(rfr, params, scoring='accuracy', cv=5)\n",
    "grid_rfr.fit(X_train, y_train)\n",
    "grid_rfr.best_params_ , grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 100}, 0.6644971966892542)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators': [100,300,600]}\n",
    "grid_rfr = GridSearchCV(rfr, params, scoring='accuracy', cv=5)\n",
    "grid_rfr.fit(X_train, y_train)\n",
    "grid_rfr.best_params_ , grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6644971966892542"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth': [3, 6, 9,12]}\n",
    "grid_rfr = GridSearchCV(rfr, params, scoring='accuracy', cv=5)\n",
    "grid_rfr.fit(X_train, y_train)\n",
    "grid_rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4127685028829484"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth': [2,3,4,5]}\n",
    "grid_rfr = GridSearchCV(rfr, params, scoring='accuracy', cv=5)\n",
    "grid_rfr.fit(X_train, y_train)\n",
    "grid_rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33250224999052924"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth': [1,1.5,2]}\n",
    "grid_rfr = GridSearchCV(rfr, params, scoring='accuracy', cv=5)\n",
    "grid_rfr.fit(X_train, y_train)\n",
    "grid_rfr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2489949618126286"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfr.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609139882424788"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbr = XGBRegressor()\n",
    "xgbr.fit(X_train, y_train)\n",
    "y_hat_xgb = xgbr.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_hat_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_hat_xgb)\n",
    "r2_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>62.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>84.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-09</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>72.3</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>80.2</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소      오존  일산화탄소     아황산    미세   초미세\n",
       "측정일시                                                \n",
       "2023-12-07  0.026  0.0184   0.50  0.0033  62.2  16.5\n",
       "2023-12-08  0.029  0.0300   0.56  0.0031  84.2  22.8\n",
       "2023-12-09  0.027  0.0379   0.61  0.0029  72.3  30.7\n",
       "2023-12-10  0.025  0.0209   0.67  0.0029  80.2  35.6\n",
       "2023-12-11  0.015  0.0227   0.40  0.0024   7.2   3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 피쳐 및 타겟 분리\n",
    "features = df[['이산화질소', '오존', '일산화탄소', '아황산', '초미세']]\n",
    "target = df['미세']\n",
    "\n",
    "# 피쳐 스케일링\n",
    "scaler_features = MinMaxScaler()\n",
    "features_scaled = scaler_features.fit_transform(features)\n",
    "\n",
    "# 타겟 스케일링\n",
    "scaler_target = MinMaxScaler()\n",
    "target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 30\n",
    "n_features = features.shape[1]\n",
    "generator = TimeseriesGenerator(features_scaled, target_scaled, length=n_input, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# EarlyStopping 콜백 설정 조기종료\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0019\n",
      "Epoch 2/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0016\n",
      "Epoch 3/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0016\n",
      "Epoch 4/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0016\n",
      "Epoch 5/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0016\n",
      "Epoch 6/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0016\n",
      "Epoch 7/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0016\n",
      "Epoch 8/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 9/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 10/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 11/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 12/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 13/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 14/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 15/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0015\n",
      "Epoch 16/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 17/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 18/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 19/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 20/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 21/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 22/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 23/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0015\n",
      "Epoch 24/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 25/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 26/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 27/100\n",
      "4274/4274 [==============================] - 31s 7ms/step - loss: 0.0014\n",
      "Epoch 28/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 29/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 30/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 31/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 32/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0014\n",
      "Epoch 33/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 34/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 35/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 36/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0014\n",
      "Epoch 37/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0014\n",
      "Epoch 38/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0014\n",
      "Epoch 39/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0014\n",
      "Epoch 40/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0013\n",
      "Epoch 41/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 42/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 43/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0013\n",
      "Epoch 44/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 45/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 46/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0013\n",
      "Epoch 47/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 48/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 49/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 50/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 51/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 52/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0013\n",
      "Epoch 53/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 54/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 55/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 56/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 57/100\n",
      "4274/4274 [==============================] - 28s 6ms/step - loss: 0.0013\n",
      "Epoch 58/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 59/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 60/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 61/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 62/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 63/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 64/100\n",
      "4274/4274 [==============================] - 28s 6ms/step - loss: 0.0013\n",
      "Epoch 65/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 66/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 67/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 68/100\n",
      "4274/4274 [==============================] - 28s 6ms/step - loss: 0.0013\n",
      "Epoch 69/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 70/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 71/100\n",
      "4274/4274 [==============================] - 28s 6ms/step - loss: 0.0013\n",
      "Epoch 72/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 73/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 74/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 75/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 76/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 77/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 78/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 79/100\n",
      "4274/4274 [==============================] - 28s 6ms/step - loss: 0.0013\n",
      "Epoch 80/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 81/100\n",
      "4274/4274 [==============================] - 27s 6ms/step - loss: 0.0013\n",
      "Epoch 82/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 83/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 84/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0013\n",
      "Epoch 85/100\n",
      "4274/4274 [==============================] - 28s 7ms/step - loss: 0.0013\n",
      "Epoch 86/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 87/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0013\n",
      "Epoch 88/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0012\n",
      "Epoch 89/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 90/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 91/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 92/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 93/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 94/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0012\n",
      "Epoch 95/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 96/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 97/100\n",
      "4274/4274 [==============================] - 30s 7ms/step - loss: 0.0012\n",
      "Epoch 98/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 99/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n",
      "Epoch 100/100\n",
      "4274/4274 [==============================] - 29s 7ms/step - loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e757d86190>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 with EarlyStopping\n",
    "model.fit(generator, epochs=100, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>62.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>84.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-09</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>72.3</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>80.2</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소      오존  일산화탄소     아황산    미세   초미세\n",
       "측정일시                                                \n",
       "2023-12-07  0.026  0.0184   0.50  0.0033  62.2  16.5\n",
       "2023-12-08  0.029  0.0300   0.56  0.0031  84.2  22.8\n",
       "2023-12-09  0.027  0.0379   0.61  0.0029  72.3  30.7\n",
       "2023-12-10  0.025  0.0209   0.67  0.0029  80.2  35.6\n",
       "2023-12-11  0.015  0.0227   0.40  0.0024   7.2   3.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4274/4274 [==============================] - 11s 2ms/step\n",
      "R^2 Score: 0.5005735436162553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 테스트 데이터셋 준비 (예시)\n",
    "# 이 부분은 실제 데이터셋과 상황에 맞게 조정해야 합니다.\n",
    "# test_features_scaled, test_target_scaled는 테스트 데이터의 스케일된 피쳐와 타겟입니다.\n",
    "test_generator = TimeseriesGenerator(features_scaled , target_scaled, length=n_input, batch_size=1)\n",
    "\n",
    "# 테스트 데이터셋에 대한 예측 수행\n",
    "test_predictions = model.predict(test_generator)\n",
    "\n",
    "# 예측값 역 스케일링\n",
    "test_predictions_inverse = scaler_target.inverse_transform(test_predictions)\n",
    "\n",
    "# 실제 타겟 값 역 스케일링\n",
    "actual_target = scaler_target.inverse_transform(target_scaled[n_input:])\n",
    "\n",
    "# R^2 값 계산\n",
    "r2 = r2_score(actual_target, test_predictions_inverse)\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.164758]]\n"
     ]
    }
   ],
   "source": [
    "# 최근 데이터를 사용한 예측\n",
    "x_input = features_scaled[-n_input:]\n",
    "x_input = x_input.reshape((1, n_input, n_features))\n",
    "predicted = model.predict(x_input, verbose=0)\n",
    "\n",
    "# 예측값 역 스케일링\n",
    "predicted_inverse = scaler_target.inverse_transform(predicted)\n",
    "print(predicted_inverse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# 데이터셋 생성\n",
    "n_input = 1  # 입력으로 사용할 일 수\n",
    "n_features = df.shape[1]  # 특성의 수\n",
    "generator = TimeseriesGenerator(data_scaled, data_scaled, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4303/4303 [==============================] - 9s 2ms/step - loss: 0.0188\n",
      "Epoch 2/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0186\n",
      "Epoch 3/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0186\n",
      "Epoch 4/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0186\n",
      "Epoch 5/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 6/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 7/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 8/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 9/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 10/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 11/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 12/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 13/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 14/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 15/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 16/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 17/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 18/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 19/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 20/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 21/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 22/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 23/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 24/100\n",
      "4303/4303 [==============================] - 10s 2ms/step - loss: 0.0185\n",
      "Epoch 25/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 26/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 27/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 28/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 29/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 30/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 31/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 32/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 33/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 34/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 35/100\n",
      "4303/4303 [==============================] - 9s 2ms/step - loss: 0.0185\n",
      "Epoch 36/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 37/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 38/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 39/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 40/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 41/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 42/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 43/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 44/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 45/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 46/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 47/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 48/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 49/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 50/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 51/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 52/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 53/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 54/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 55/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 56/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 57/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 58/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 59/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 60/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 61/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 62/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 63/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 64/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 65/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 66/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 67/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 68/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 69/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 70/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 71/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 72/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 73/100\n",
      "4303/4303 [==============================] - 9s 2ms/step - loss: 0.0185\n",
      "Epoch 74/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 75/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 76/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 77/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 78/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 79/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 80/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 81/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 82/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 83/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 84/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 85/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 86/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 87/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 88/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 89/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 90/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 91/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 92/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 93/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 94/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 95/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 96/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 97/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 98/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n",
      "Epoch 99/100\n",
      "4303/4303 [==============================] - 8s 2ms/step - loss: 0.0185\n",
      "Epoch 100/100\n",
      "4303/4303 [==============================] - 7s 2ms/step - loss: 0.0185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e74792d510>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016476395294070245\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과 확장\n",
    "predicted_expanded = np.zeros((1, 6))\n",
    "predicted_expanded[0, 0] = predicted  # 첫 번째 특성에 예측값 할당, 나머지는 0\n",
    "\n",
    "# 스케일 역변환\n",
    "predicted_inverse = scaler.inverse_transform(predicted_expanded)\n",
    "print(predicted_inverse[0, 0])  # 첫 번째 특성의 역변환된 값을 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_input, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 스케일 역변환\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted)\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:547\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    541\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    543\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    544\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m )\n\u001b[1;32m--> 547\u001b[0m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_\u001b[49m\n\u001b[0;32m    548\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,6)"
     ]
    }
   ],
   "source": [
    "# 하루 뒤 예측\n",
    "x_input = data_scaled[-n_input:]  # 마지막 데이터\n",
    "x_input = x_input.reshape((1, n_input, n_features))\n",
    "predicted = model.predict(x_input, verbose=0)\n",
    "\n",
    "# 스케일 역변환\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "108/108 [==============================] - 9s 43ms/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 4s 38ms/step - loss: 0.0020 - val_loss: 9.8798e-04\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 5s 42ms/step - loss: 0.0017 - val_loss: 7.6178e-04\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 4s 40ms/step - loss: 0.0016 - val_loss: 7.9433e-04\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0015 - val_loss: 6.3849e-04\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0015 - val_loss: 7.5981e-04\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0015 - val_loss: 7.3303e-04\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0014 - val_loss: 7.6424e-04\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0015 - val_loss: 6.4766e-04\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0014 - val_loss: 6.5256e-04\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0015 - val_loss: 6.8834e-04\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0014 - val_loss: 6.5358e-04\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0013 - val_loss: 7.4795e-04\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.5026e-04\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0013 - val_loss: 6.6272e-04\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0014 - val_loss: 6.4894e-04\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 0.0013 - val_loss: 6.6044e-04\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0014 - val_loss: 6.7622e-04\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.4509e-04\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.7948e-04\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.4086e-04\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.3087e-04\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.8727e-04\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.3692e-04\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0014 - val_loss: 8.3358e-04\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0013 - val_loss: 6.3458e-04\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0013 - val_loss: 6.4795e-04\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.0013 - val_loss: 7.4781e-04\n",
      "12/12 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.9 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 60  # 수치구성방법 총 데이터의수 20%가 최대치 (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 4])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 4])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# 예측 및 역변환\n",
    "prediction = model.predict(testX)\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (Coefficient of Determination): 0.32682585351060767\n",
      "Mean Squared Error: 1.3305178309934127e-05\n",
      "Mean Absolute Error: 0.002137832238375317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# R² 값 계산\n",
    "r_squared = r2_score(testY_transformed, prediction_transformed)\n",
    "# MSE 및 MAE 계산\n",
    "mse = mean_squared_error(testY_transformed, prediction_transformed)\n",
    "mae = mean_absolute_error(testY_transformed, prediction_transformed)\n",
    "\n",
    "\n",
    "print(\"R-squared (Coefficient of Determination):\", r_squared)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "최신 데이터에 대한 예측된 값: 0.011555720355361702\n"
     ]
    }
   ],
   "source": [
    "# 최신 데이터 시퀀스 추출\n",
    "latest_seq_len = 60  # 예측에 사용할 최신 데이터의 길이\n",
    "latest_data = test_data[-latest_seq_len:].reshape(1, latest_seq_len, input_dim)\n",
    "\n",
    "# 예측 수행\n",
    "latest_prediction = model.predict(latest_data)\n",
    "\n",
    "# 예측 결과 역변환\n",
    "latest_prediction_transformed = scaler.inverse_transform(np.concatenate((latest_prediction, np.zeros((latest_prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 예측된 결과 출력\n",
    "predicted_value = latest_prediction_transformed[0]\n",
    "print(\"최신 데이터에 대한 예측된 값:\", predicted_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05118787], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "측정일시\n",
       "2012-01-01    0.0080\n",
       "2012-01-02    0.0050\n",
       "2012-01-03    0.0063\n",
       "2012-01-04    0.0130\n",
       "2012-01-05    0.0073\n",
       "               ...  \n",
       "2023-12-07    0.0184\n",
       "2023-12-08    0.0300\n",
       "2023-12-09    0.0379\n",
       "2023-12-10    0.0209\n",
       "2023-12-11    0.0227\n",
       "Name: 오존, Length: 4304, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['오존']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (Coefficient of Determination): 0.14345537992452617\n",
      "Mean Squared Error: 3.4053615925011035e-06\n",
      "Mean Absolute Error: 0.001398751600554905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# R² 값 계산\n",
    "r_squared = r2_score(testY_transformed, prediction_transformed)\n",
    "# MSE 및 MAE 계산\n",
    "mse = mean_squared_error(testY_transformed, prediction_transformed)\n",
    "mae = mean_absolute_error(testY_transformed, prediction_transformed)\n",
    "\n",
    "\n",
    "print(\"R-squared (Coefficient of Determination):\", r_squared)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "27/27 [==============================] - 10s 244ms/step - loss: 0.0523 - val_loss: 0.0094\n",
      "Epoch 2/130\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0154 - val_loss: 0.0086\n",
      "Epoch 3/130\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 4/130\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0140 - val_loss: 0.0081\n",
      "Epoch 5/130\n",
      "27/27 [==============================] - 6s 212ms/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 6/130\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 7/130\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0117 - val_loss: 0.0072\n",
      "Epoch 8/130\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 9/130\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 10/130\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 11/130\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 12/130\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.0102 - val_loss: 0.0064\n",
      "Epoch 13/130\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 14/130\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 15/130\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 16/130\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 17/130\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 18/130\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 19/130\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 20/130\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 21/130\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 22/130\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 23/130\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 24/130\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 25/130\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 26/130\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 27/130\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 28/130\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 29/130\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 30/130\n",
      "27/27 [==============================] - 6s 212ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "11/11 [==============================] - 1s 32ms/step\n",
      "R2 점수: 0.458878333052373\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.9 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 100  # 수치구성방법 총 데이터의수 20%가 최대치 (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 0])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.008), loss='mse')\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(trainX, trainY, epochs=130, batch_size=128, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(testX)\n",
    "\n",
    "# 예측값 역변환\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 실제 타겟값 역변환\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 722ms/step\n",
      "최신 데이터에 대한 예측된 값: 0.02375040049850941\n"
     ]
    }
   ],
   "source": [
    "# 최신 데이터 시퀀스 추출\n",
    "latest_seq_len = 60  # 예측에 사용할 최신 데이터의 길이\n",
    "latest_data = test_data[-latest_seq_len:].reshape(1, latest_seq_len, input_dim)\n",
    "\n",
    "# 예측 수행\n",
    "latest_prediction = model.predict(latest_data)\n",
    "\n",
    "# 예측 결과 역변환\n",
    "latest_prediction_transformed = scaler.inverse_transform(np.concatenate((latest_prediction, np.zeros((latest_prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 예측된 결과 출력\n",
    "predicted_value = latest_prediction_transformed[0]\n",
    "print(\"최신 데이터에 대한 예측된 값:\", predicted_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>오존</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산</th>\n",
       "      <th>미세</th>\n",
       "      <th>초미세</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>측정일시</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>62.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>84.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-09</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>72.3</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>80.2</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            이산화질소      오존  일산화탄소     아황산    미세   초미세\n",
       "측정일시                                                \n",
       "2023-12-07  0.026  0.0184   0.50  0.0033  62.2  16.5\n",
       "2023-12-08  0.029  0.0300   0.56  0.0031  84.2  22.8\n",
       "2023-12-09  0.027  0.0379   0.61  0.0029  72.3  30.7\n",
       "2023-12-10  0.025  0.0209   0.67  0.0029  80.2  35.6\n",
       "2023-12-11  0.015  0.0227   0.40  0.0024   7.2   3.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NO2_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "27/27 [==============================] - 8s 191ms/step - loss: 0.0683 - val_loss: 0.0150\n",
      "Epoch 2/130\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 0.0114 - val_loss: 0.0146\n",
      "Epoch 3/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0111 - val_loss: 0.0162\n",
      "Epoch 4/130\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 0.0105 - val_loss: 0.0142\n",
      "Epoch 5/130\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 6/130\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 7/130\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 8/130\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 9/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0093 - val_loss: 0.0124\n",
      "Epoch 10/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 11/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 12/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 13/130\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 14/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 15/130\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 16/130\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 17/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 18/130\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 19/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 20/130\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 21/130\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 22/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 23/130\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 24/130\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 25/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 26/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 27/130\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 28/130\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 29/130\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 0.0083 - val_loss: 0.0130\n",
      "Epoch 30/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 31/130\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 32/130\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 33/130\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 34/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 35/130\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 36/130\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 37/130\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0081 - val_loss: 0.0112\n",
      "11/11 [==============================] - 1s 23ms/step\n",
      "R2 점수: 0.6449530034121795\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.9 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 100  # 수치구성방법 총 데이터의수 20%가 최대치 (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 1])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 1])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.008), loss='mse')\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(trainX, trainY, epochs=130, batch_size=128, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(testX)\n",
    "\n",
    "# 예측값 역변환\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 실제 타겟값 역변환\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/O3_model.h5')  # 한글 이름 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 13s 106ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 8s 93ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 9s 107ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 8s 93ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 8s 93ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 8s 93ms/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 8s 92ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 8s 91ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 8s 94ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 8s 95ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 9s 103ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 9s 102ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 8s 95ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 8s 99ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 8s 101ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 9s 102ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 8s 97ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 8s 95ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 8s 101ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 8s 94ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 9s 101ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 8s 98ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 8s 98ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 8s 98ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "24/24 [==============================] - 2s 36ms/step\n",
      "R2 점수: 0.50592129030926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화 (훈련 데이터에만 fit 적용)\n",
    "scaler = MinMaxScaler()\n",
    "n_train = int(0.8 * len(data))\n",
    "train_data = data[:n_train]\n",
    "test_data = data[n_train:]\n",
    "\n",
    "scaler.fit(train_data)  # Fit only on training data\n",
    "train_data_scaled = scaler.transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 100\n",
    "input_dim = train_data_scaled.shape[1]\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data_scaled)):\n",
    "    trainX.append(train_data_scaled[i-seq_len:i, :])\n",
    "    trainY.append(train_data_scaled[i, 5])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data_scaled)):\n",
    "    testX.append(test_data_scaled[i-seq_len:i, :])\n",
    "    testY.append(test_data_scaled[i, 5])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측 및 역변환\n",
    "prediction = model.predict(testX)\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data.shape[1]-1))), axis=1))[:,0]\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddddddddddddddd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mddddddddddddddd\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ddddddddddddddd' is not defined"
     ]
    }
   ],
   "source": [
    "ddddddddddddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "내일의 예측된 값: 0.05987326008081437\n"
     ]
    }
   ],
   "source": [
    "def predict_next_day(model, initial_seq, seq_len, input_dim):\n",
    "    current_seq = initial_seq.copy()\n",
    "    current_seq_reshaped = current_seq.reshape(1, seq_len, input_dim)\n",
    "    next_prediction = model.predict(current_seq_reshaped)\n",
    "\n",
    "    return next_prediction[0, 0]\n",
    "\n",
    "# 최신 데이터 시퀀스 준비\n",
    "latest_seq_len = 100  # 예측에 사용할 최신 데이터의 길이\n",
    "latest_data = test_data[-latest_seq_len:].reshape(seq_len, input_dim)\n",
    "\n",
    "# 내일의 값 예측\n",
    "predicted_value_for_next_day = predict_next_day(model, latest_data, seq_len, input_dim)\n",
    "\n",
    "# 예측 결과 역변환\n",
    "predicted_value_transformed = scaler.inverse_transform([[predicted_value_for_next_day] + [0] * (data_scaled.shape[1] - 1)])\n",
    "\n",
    "print(\"내일의 예측된 값:\", predicted_value_transformed[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최신 데이터에 대한 예측된 값: 0.019941310375603587\n"
     ]
    }
   ],
   "source": [
    "# 최신 데이터 시퀀스 추출\n",
    "latest_seq_len = 100  # 예측에 사용할 최신 데이터의 길이\n",
    "latest_data = test_data[-latest_seq_len:].reshape(1, latest_seq_len, input_dim)\n",
    "\n",
    "# 예측 수행\n",
    "latest_prediction = model.predict(latest_data)\n",
    "\n",
    "# 예측 결과 역변환 (여기서 오류가 발생했을 수 있음)\n",
    "latest_prediction_transformed = scaler.inverse_transform(np.concatenate((latest_prediction, np.zeros((latest_prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 예측된 결과 출력\n",
    "predicted_value = latest_prediction_transformed[0]\n",
    "print(\"최신 데이터에 대한 예측된 값:\", predicted_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 8s 68ms/step - loss: 0.8003 - val_loss: 1.0866\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 5s 60ms/step - loss: 0.7199 - val_loss: 1.0379\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 5s 60ms/step - loss: 0.6574 - val_loss: 0.9857\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 5s 60ms/step - loss: 0.5886 - val_loss: 0.9220\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 0.5633 - val_loss: 0.8786\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 0.5409 - val_loss: 0.8371\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 0.5381 - val_loss: 0.8572\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 0.5234 - val_loss: 0.8312\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 0.5208 - val_loss: 0.8248\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 0.5104 - val_loss: 0.7927\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 0.5009 - val_loss: 0.8080\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.5004 - val_loss: 0.7912\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.4874 - val_loss: 0.7813\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 0.4834 - val_loss: 0.7787\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.4804 - val_loss: 0.7914\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.4653 - val_loss: 0.7558\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 0.4606 - val_loss: 0.8084\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 0.4533 - val_loss: 0.7893\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.4520 - val_loss: 0.7945\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 0.4388 - val_loss: 0.7966\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 0.4275 - val_loss: 0.8197\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 0.4228 - val_loss: 0.8033\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 5s 65ms/step - loss: 0.4132 - val_loss: 0.7886\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 0.4100 - val_loss: 0.7747\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 0.3979 - val_loss: 0.7920\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 0.3896 - val_loss: 0.7861\n",
      "24/24 [==============================] - 1s 34ms/step\n",
      "R2 점수: 0.4469042576411071\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.8 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 100  # 수치구성방법 총 데이터의수 20%가 최대치 (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 4])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 4])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(testX)\n",
    "\n",
    "# 예측값 역변환\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 실제 타겟값 역변환\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/PM10_model.h5')  # 한글 이름 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "101/101 [==============================] - 5s 32ms/step - loss: 0.0160 - val_loss: 0.0082\n",
      "Epoch 2/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 3/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 4/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 5/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0119 - val_loss: 0.0069\n",
      "Epoch 6/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0118 - val_loss: 0.0068\n",
      "Epoch 7/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 8/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 9/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 10/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0114 - val_loss: 0.0068\n",
      "Epoch 11/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 12/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 13/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 14/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 15/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 16/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 17/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 18/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0104 - val_loss: 0.0066\n",
      "Epoch 19/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 20/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0099 - val_loss: 0.0059\n",
      "Epoch 21/120\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 22/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 23/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 24/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 25/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 26/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 27/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 28/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 29/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 30/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 31/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 32/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 33/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 34/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 35/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 36/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 37/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 38/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 39/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 40/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 41/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 42/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 43/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 44/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 45/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 46/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 47/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 48/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 49/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 50/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 51/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 52/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 53/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 54/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 55/120\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 56/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0083 - val_loss: 0.0049\n",
      "Epoch 57/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 58/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 59/120\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 60/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 61/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 62/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 63/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 64/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 65/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 66/120\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 67/120\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 68/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 69/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 70/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 71/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 72/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 73/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 74/120\n",
      "101/101 [==============================] - 3s 27ms/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 75/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 76/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 77/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 78/120\n",
      "101/101 [==============================] - 3s 29ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 79/120\n",
      "101/101 [==============================] - 3s 31ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 80/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 81/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 82/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 83/120\n",
      "101/101 [==============================] - 3s 30ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 84/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 85/120\n",
      "101/101 [==============================] - 3s 28ms/step - loss: 0.0080 - val_loss: 0.0048\n",
      "12/12 [==============================] - 1s 13ms/step\n",
      "R2 점수: 0.5465857586105638\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.9 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 70  # 수치구성방법 총 데이터의수 20%가 최대치 (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 2])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 2])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(trainX, trainY, epochs=120, batch_size=32, validation_split=0.15, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(testX)\n",
    "\n",
    "# 예측값 역변환\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 실제 타겟값 역변환\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/co.h5')  # 한글 이름 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 7s 83ms/step - loss: 0.0051 - val_loss: 4.9927e-04\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0031 - val_loss: 5.4146e-04\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0030 - val_loss: 4.3067e-04\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0030 - val_loss: 5.1402e-04\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0030 - val_loss: 5.0965e-04\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0029 - val_loss: 4.5977e-04\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0028 - val_loss: 5.7101e-04\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0028 - val_loss: 9.1865e-04\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0028 - val_loss: 4.5581e-04\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0027 - val_loss: 4.8084e-04\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0027 - val_loss: 4.8583e-04\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0026 - val_loss: 4.7214e-04\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0025 - val_loss: 3.7418e-04\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.0024 - val_loss: 4.0581e-04\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.0023 - val_loss: 3.4190e-04\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.0023 - val_loss: 4.8513e-04\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.0022 - val_loss: 4.5214e-04\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.0023 - val_loss: 3.1126e-04\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0023 - val_loss: 3.0755e-04\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.0022 - val_loss: 4.2154e-04\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0022 - val_loss: 3.8555e-04\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0022 - val_loss: 4.9773e-04\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0022 - val_loss: 3.9062e-04\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0022 - val_loss: 3.2355e-04\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0021 - val_loss: 5.5930e-04\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.0022 - val_loss: 3.3659e-04\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.0021 - val_loss: 3.8972e-04\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.0022 - val_loss: 3.2733e-04\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0021 - val_loss: 3.4074e-04\n",
      "11/11 [==============================] - 1s 19ms/step\n",
      "R2 점수: 0.4295381455093369\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 데이터셋 준비 (이미 원-핫 인코딩 및 NaN 처리 완료)\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터셋 분할\n",
    "n_train = int(0.9 * len(data_scaled))\n",
    "train_data = data_scaled[:n_train]\n",
    "test_data = data_scaled[n_train:]\n",
    "train_dates = df.index[:n_train]\n",
    "test_dates = df.index[n_train:]\n",
    "\n",
    "# 데이터셋 재구성\n",
    "seq_len = 100  # 수치길이는 1이 하루를 의미함 4계절 대한민국이라 그것을 참고해서 정함  (수치를 조정해서 모델 적중률 조정)\n",
    "input_dim = train_data.shape[1]  # 입력 차원 (원-핫 인코딩된 열의 수)\n",
    "\n",
    "trainX, trainY = [], []\n",
    "testX, testY = [], []\n",
    "\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    trainX.append(train_data[i-seq_len:i, :])\n",
    "    trainY.append(train_data[i, 3])  # 첫 번째 열이 타겟 변수라고 가정\n",
    "\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    testX.append(test_data[i-seq_len:i, :])\n",
    "    testY.append(test_data[i, 3])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX, testY = np.array(testX), np.array(testY)\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, input_dim), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # 하나의 출력 뉴런\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(testX)\n",
    "\n",
    "# 예측값 역변환\n",
    "prediction_transformed = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 실제 타겟값 역변환\n",
    "testY_transformed = scaler.inverse_transform(np.concatenate((testY.reshape(-1,1), np.zeros((testY.shape[0], data_scaled.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# R2 점수 계산\n",
    "r2 = r2_score(testY_transformed, prediction_transformed)\n",
    "print(\"R2 점수:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SO2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이산화질소', '오존', '일산화탄소', '아황산', '미세', '초미세'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치의 개수: 89\n",
      "이상치 인덱스와 값:\n",
      "측정일시\n",
      "2012-01-01    0.010\n",
      "2012-01-02    0.009\n",
      "2012-01-04    0.011\n",
      "2012-01-07    0.009\n",
      "2012-01-08    0.009\n",
      "              ...  \n",
      "2015-03-15    0.009\n",
      "2015-03-16    0.009\n",
      "2015-03-17    0.011\n",
      "2015-03-21    0.013\n",
      "2018-02-27    0.009\n",
      "Name: 아황산, Length: 89, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 'df'와 컬럼 이름 'column_name'을 가정\n",
    "column_name = 'your_column_name'\n",
    "data = df['아황산']\n",
    "\n",
    "# IQR 계산\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 이상치 탐지\n",
    "outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# 이상치 출력\n",
    "print(\"이상치의 개수:\", outliers.sum())\n",
    "print(\"이상치 인덱스와 값:\")\n",
    "print(data[outliers])\n",
    "\n",
    "# 이상치 시각화 (선택적)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
